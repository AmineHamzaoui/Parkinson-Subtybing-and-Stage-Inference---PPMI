{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf6ecea-b7f1-453f-a471-d993ab09356a",
   "metadata": {},
   "source": [
    "###\n",
    "# pySuStaIn: a Python implementation of the Subtype and Stage Inference (SuStaIn) algorithm\n",
    "#\n",
    "# If you use pySuStaIn, please cite the following core papers:\n",
    "# 1. The original SuStaIn paper:    https://doi.org/10.1038/s41467-018-05892-0\n",
    "# 2. The pySuStaIn software paper:  https://doi.org/10.1016/j.softx.2021.100811\n",
    "\n",
    "# Please also cite the corresponding progression pattern model you use:\n",
    "# 1. The piece-wise linear z-score model (i.e. ZscoreSustain):  https://do i.org/10.1038/s41467-018-05892-0\n",
    "# 2. The event-based model (i.e. MixtureSustain):               https://doi.org/10.1016/j.neuroimage.2012.01.062\n",
    "#    with Gaussian mixture modeling (i.e. 'mixture_gmm'):       https://doi.org/10.1093/brain/awu176\n",
    "#    or kernel density estimation (i.e. 'mixture_kde'):         https://doi.org/10.1002/alz.12083\n",
    "# 3. The model for discrete ordinal data (i.e. OrdinalSustain): https://doi.org/10.3389/frai.2021.613261\n",
    "#\n",
    "# Thanks a lot for supporting this project.\n",
    "#\n",
    "# Authors:      Peter Wijeratne (p.wijeratne@ucl.ac.uk) and Leon Aksman (leon.aksman@loni.usc.edu)\n",
    "# Contributors: Arman Eshaghi (a.eshaghi@ucl.ac.uk), Alex Young (alexandra.young@kcl.ac.uk), Cameron Shand (c.shand@ucl.ac.uk)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d778831-3e92-4003-bc43-f80386b64a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Visit' and calculate percentage of missing values per column\n",
    "missing_percent_by_visit = (\n",
    "    df.groupby('EVENT_ID')\n",
    "      .apply(lambda g: g.isnull().mean() * 100)\n",
    "      .round(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ee4a2-0e4a-4c92-b4e8-68a3c8d5ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent_by_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad81d2-c18d-4c8e-bc6d-bb18d9580e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent_by_visit.to_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/missing_precentage_per_visit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e309f-a56a-4f69-a576-8ddbb1970f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_visits = [\"V04\", \"V06\", \"V08\"]\n",
    "cog_cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\"]\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + cog_cols + [\"EVENT_ID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27ae28-8d12-4014-9cc6-8f02b7b1c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"EVENT_ID\"].isin(required_visits)][selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2eb59-1c71-4412-9f1b-91eec4d57c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89ddeb-596e-4a59-8e24-c42fbe51235a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3022a6-1919-46c3-bd42-6875d6237a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the python packages needed to generate simulated data for the tutorial\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import sys\n",
    "import pySuStaIn\n",
    "\n",
    "# this needs to point to wherever the sim folder inside pySuStaIn is on your computer\n",
    "#sys.path.insert(0,'/Users/alexandrayoung/Documents/Code/pySuStaIn-test/pySuStaIn/sim/')\n",
    "# if you're running the notebook from within the existing structure you can use\n",
    "sys.path.insert(0,'../sim/')\n",
    "from simfuncs import generate_random_Zscore_sustain_model, generate_data_Zscore_sustain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87c7ef-c281-4748-a195-6cb29e4b1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = df[df[\"COHORT\"].isin([\"Healthy Control\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e03649-2725-4c40-a986-0ba8e866cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Drop any PATNO who has missing values in any of those columns\n",
    "def is_patient_valid(group):\n",
    "    return (len(group) == 3) and (not group[cog_cols].isnull().any().any())\n",
    "\n",
    "df_control = df_control.groupby(\"PATNO\").filter(is_patient_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cffba0-31d3-4f18-abd2-ffe090124703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db7b79-fb40-4011-a300-8c7a371904ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_pd = df_prod_pd.groupby(\"PATNO\").filter(is_patient_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e93cf-ac90-451b-81dd-97ed5fa26413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d131164-b7c6-40dc-b12c-f045b9d43aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_selected=  df_control[[\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce2701-d94f-4719-b16c-86e724b75ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a16a6-d143-483c-9f5d-3ec0a395c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_prod_selected=df_prod_pd[[\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3e951-1d94-4a8e-bb4c-94d93b3b0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data for control subjects\n",
    "\n",
    "\n",
    "# compute the mean and standard deviation of the control population\n",
    "mean_control = np.mean(df_control_selected,axis=0)\n",
    "std_control = np.std(df_control_selected,axis=0)\n",
    "\n",
    "# z-score the data\n",
    "data = (df_pd_prod_selected-mean_control)/std_control\n",
    "data_control = (df_control_selected-mean_control)/std_control\n",
    "\n",
    "# multiply data for decreasing biomarkers by -1\n",
    "#is_decreasing = np.mean(data,axis=0)<np.mean(data_control,axis=0)\n",
    "#data.loc[:, is_decreasing] = data.loc[:, is_decreasing] * -1\n",
    "\n",
    "# For data_control\n",
    "#data_control.loc[:, is_decreasing] = data_control.loc[:, is_decreasing] * -1\n",
    "\n",
    "# Check that the mean of the control population is 0\n",
    "#print('Mean of controls is ',np.mean(data_control,axis=0))\n",
    "# Check that the standard deviation of the control population is 1\n",
    "#print('Standard deviation of controls is ',np.std(data_control,axis=0))\n",
    "# Check that the mean of the whole dataset is positive\n",
    "#print('Mean of whole dataset is ',np.mean(data,axis=0))\n",
    "# Check that the standard deviation of the whole dataset is greater than 1\n",
    "#print('Standard deviation of whole dataset is ',np.std(data,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cab68f-22c0-41b2-bc54-d74a989ea541",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c9078-7ec8-4175-91ef-df98ea9880fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5ed07-fae0-413e-aa75-943a631bb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\"]\n",
    "\n",
    "for col in cols:\n",
    "    df_mean = df_prod_pd.groupby('EVENT_ID', as_index=False)[col].mean()\n",
    "    \n",
    "    sns.lineplot(data=df_mean, x='EVENT_ID', y=col)\n",
    "    plt.title(f\"Average {col} Across Visits\")\n",
    "    plt.xlabel(\"Visit (EVENT_ID)\")\n",
    "    plt.ylabel(f\"Average {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a5e52-9d95-4ed0-a251-602240bcbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vérification des intervalles\n",
    "Formule pour valeur de dépression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a11dbb-5756-46c7-979d-6af1345fc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\"]\n",
    "\n",
    "for col in cols:\n",
    "    df_mean = df_control.groupby('EVENT_ID', as_index=False)[col].mean()\n",
    "    \n",
    "    sns.lineplot(data=df_mean, x='EVENT_ID', y=col)\n",
    "    plt.title(f\"Average {col} Across Visits\")\n",
    "    plt.xlabel(\"Visit (EVENT_ID)\")\n",
    "    plt.ylabel(f\"Average {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236e399-5295-4410-a43d-4d3a9de7dc81",
   "metadata": {},
   "source": [
    "# Zmax selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd1cdb-c49b-4606-9ffd-1f5ffd61562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\"]\n",
    "percentiles_95 = data[cols].quantile(0.95)\n",
    "print(\"95th percentiles:\")\n",
    "print(percentiles_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe36fa6-0a91-49f4-af08-52ac233f4440",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566067b-156a-4ba0-a844-7125fc0bdfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b88eb-c3a9-46ee-94fd-5e720d7cdf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded35ea-d78a-42bd-90ca-9d5eb7ded5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fc267-0b8b-4d3a-9381-9908da64a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_median_zscores(data):\n",
    "    \"\"\"\n",
    "    Plots median and IQR for each biomarker in z-scored data.\n",
    "    \"\"\"\n",
    "    if isinstance(data, np.ndarray):\n",
    "        data = pd.DataFrame(data, columns=[f\"Biomarker {i+1}\" for i in range(data.shape[1])])\n",
    "\n",
    "    medians = data.median()\n",
    "    q25 = data.quantile(0.1)\n",
    "    q75 = data.quantile(0.99)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(medians.index, medians.values, marker='o', label='Median z-score')\n",
    "    plt.fill_between(medians.index, q25, q75, alpha=0.2, label='IQR (25–75%)')\n",
    "\n",
    "    plt.axhline(1, color='gray', linestyle='--', label='Z=1')\n",
    "    plt.axhline(2, color='gray', linestyle='--', label='Z=2')\n",
    "    plt.axhline(3, color='gray', linestyle='--', label='Z=3')\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(\"Z-score\")\n",
    "    plt.title(\"Median Z-scores with IQR per Biomarker\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e1cd2-3054-4ead-8065-80cac72e8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_median_zscores(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122ee83-0e7a-4b99-8d3f-3696705d5e3e",
   "metadata": {},
   "source": [
    "## To be tweaked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4364f-c05b-42d3-8cd0-dcd505e75b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_vals = np.array([\n",
    "    [0, 1, 2, 0, 0, 0],\n",
    "    [1, 2, 4, 5, 6, 0],\n",
    "    [1, 2, 4, 5, 6, 7]\n",
    "])\n",
    "Z_max = np.array([2, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ab2a2-0af5-46bd-ad6f-b6d43c24f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_prod_selected=df_prod_pd[[\"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f2d35-15be-4b62-a4aa-04f2dbab6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data for control subjects\n",
    "\n",
    "\n",
    "# compute the mean and standard deviation of the control population\n",
    "mean_control = np.mean(df_control_selected,axis=0)\n",
    "std_control = np.std(df_control_selected,axis=0)\n",
    "\n",
    "# z-score the data\n",
    "data = (df_pd_prod_selected-mean_control)/std_control\n",
    "data_control = (df_control_selected-mean_control)/std_control\n",
    "\n",
    "# multiply data for decreasing biomarkers by -1\n",
    "#is_decreasing = np.mean(data,axis=0)<np.mean(data_control,axis=0)\n",
    "#data.loc[:, is_decreasing] = data.loc[:, is_decreasing] * -1\n",
    "\n",
    "# For data_control\n",
    "#data_control.loc[:, is_decreasing] = data_control.loc[:, is_decreasing] * -1\n",
    "\n",
    "# Check that the mean of the control population is 0\n",
    "#print('Mean of controls is ',np.mean(data_control,axis=0))\n",
    "# Check that the standard deviation of the control population is 1\n",
    "#print('Standard deviation of controls is ',np.std(data_control,axis=0))\n",
    "# Check that the mean of the whole dataset is positive\n",
    "#print('Mean of whole dataset is ',np.mean(data,axis=0))\n",
    "# Check that the standard deviation of the whole dataset is greater than 1\n",
    "#print('Standard deviation of whole dataset is ',np.std(data,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627b922-9131-4599-a52a-0c3a11cd5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee63a7-eb06-4d0f-bc28-3b7f030256ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=[\"AGE_AT_VISIT\", \"MCATOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d3490-9d61-46e0-ac8a-a1d8272fcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN\n",
    "data = data.dropna()\n",
    "\n",
    "# Remove rows with any negative values\n",
    "data=data[(data >= 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d2afd-47c8-4cfd-b759-ff7547d77c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "SuStaInLabels = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b52061-221b-4ea6-86d6-8d4a69a0e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374cec2-9fe6-486f-b610-3bba8bb8e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "SuStaInLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81232af-d273-4271-b596-a7d24b631f7d",
   "metadata": {},
   "source": [
    "Run the model after that refer to feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ad0e3-fcbf-49ab-bea7-8e0cff8edcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the settings for z-score SuStaIn\n",
    "# To make the tutorial run faster I've set \n",
    "# N_startpoints = 10 and N_iterations_MCMC = int(1e4)\n",
    "# I recommend using N_startpoints = 25 and \n",
    "# N_iterations_MCMC = int(1e5) or int(1e6) in general though\n",
    "N_startpoints = 25\n",
    "N_S_max = 2\n",
    "N_iterations_MCMC = int(1e4)\n",
    "output_folder = os.path.join(os.getcwd(), 'sim')\n",
    "dataset_name = 'ppmi'\n",
    "sustain_input = pySuStaIn.ZscoreSustain(data,\n",
    "                              Z_vals,\n",
    "                              Z_max,\n",
    "                              SuStaInLabels,\n",
    "                              N_startpoints,\n",
    "                              N_S_max, \n",
    "                              N_iterations_MCMC, \n",
    "                              output_folder, \n",
    "                              dataset_name, \n",
    "                              False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a71ad5-d5c9-45e7-9ba8-387d2af669d1",
   "metadata": {},
   "source": [
    "Deleting previous SuStaIn results if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccb11d-a893-4714-92fc-bd96f85a7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "# output_folder = os.path.join(os.getcwd(), 'sim2')    \n",
    "# dataset_name = 'sim2' \n",
    "# sustain_input = ZscoreSustain(data,\n",
    "#                               Z_vals,\n",
    "#                               Z_max,\n",
    "#                               SuStaInLabels,\n",
    "#                               N_startpoints,\n",
    "#                               N_S_max, \n",
    "#                               N_iterations_MCMC, \n",
    "#                               output_folder, \n",
    "#                               dataset_name, \n",
    "#                               False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f599f-40af-4f9a-86fe-bf8da44da65b",
   "metadata": {},
   "source": [
    "Create folder for results if it dosen't exist already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41dcbd1-f9f7-4843-80fb-57513a4445d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59601b22-4c2c-46f0-a34a-9cc129cae015",
   "metadata": {},
   "source": [
    "Running the SuStaIn algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ebacb0-a789-479a-9496-0e8d5f695c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.exists('C:\\\\Users\\\\nss_1\\\\Desktop\\\\SustalIn\\\\pySuStaIn\\\\notebooks\\\\sim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbf6a1-249e-4a3d-9fd0-962e9c44246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa1c4c-86d4-4e22-9a56-6921d9296143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runs the sustain algorithm with the inputs set in sustain_input above\n",
    "samples_sequence,   \\\n",
    "samples_f,          \\\n",
    "ml_subtype,         \\\n",
    "prob_ml_subtype,    \\\n",
    "ml_stage,           \\\n",
    "prob_ml_stage,      \\\n",
    "prob_subtype_stage  = sustain_input.run_sustain_algorithm()# Load SuStaIn inference results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc059cb-e5f5-4e25-911d-f934f1a841fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692b51f-a1a2-425b-b5ee-98390e3da575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ceb45-7558-48b2-b2ae-8fd8725af35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Z_vals shape:\", Z_vals.shape)  # should be (n_biomarkers, n_zscores)\n",
    "print(\"Expected events:\", Z_vals.shape[0] * Z_vals.shape[1])\n",
    "print(\"zvalues length:\", len(Z_vals))\n",
    "print(\"colour_mat shape:\", colour_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a142321-9d68-4ec0-86ff-f569f6194f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Z_vals shape:\", Z_vals.shape)  # Expect (n_biomarkers, n_zscore_levels)\n",
    "n_events = Z_vals.shape[0] * Z_vals.shape[1]\n",
    "print(\"Expected number of z-score events (n_events):\", n_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358bba4d-d076-4cfc-977a-7f4e14360c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zvalues = Z_vals.flatten(order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6a720-9441-4bc2-9f48-0e03f181553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846fa36-87f9-4a4b-b226-c727b8bfee2e",
   "metadata": {},
   "source": [
    "# After Adding more Continious Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a7c66-a500-4704-b1b6-4da0cd9a7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The code below opens the results for the ground truth number of subtypes\n",
    "# and plots the output\n",
    "s = 1\n",
    "pickle_filename_s           = output_folder + '/pickle_files/' + dataset_name + '_subtype' + str(s) + '.pickle'\n",
    "pickle_filepath             = Path(pickle_filename_s)\n",
    "pickle_file                 = open(pickle_filename_s, 'rb')\n",
    "loaded_variables            = pickle.load(pickle_file)\n",
    "samples_sequence            = loaded_variables[\"samples_sequence\"]\n",
    "samples_f                   = loaded_variables[\"samples_f\"]\n",
    "pickle_file.close()\n",
    "\n",
    "pySuStaIn.ZscoreSustain._plot_sustain_model(sustain_input,samples_sequence,samples_f,M,subtype_order=(0,1))\n",
    "_ = plt.suptitle('Figure 10: SuStaIn output')\n",
    "\n",
    "\n",
    "sustain_input.combine_cross_validated_sequences(N_S_gt, N_folds)\n",
    "_ = plt.suptitle('Figure 11: Cross-validated SuStaIn output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e769d5-24e8-4030-a97e-5d18b1cc0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pySuStaIn\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv', sep=';')\n",
    "\n",
    "# Define STAI items\n",
    "state_items = [f'STAIAD{i}' for i in range(1, 21)]\n",
    "trait_items = [f'STAIAD{i}' for i in range(21, 41)]\n",
    "reverse_scored_items = ['STAIAD1', 'STAIAD2', 'STAIAD5', 'STAIAD8', 'STAIAD10',\n",
    "                        'STAIAD11', 'STAIAD15', 'STAIAD16', 'STAIAD19', 'STAIAD20',\n",
    "                        'STAIAD21', 'STAIAD23', 'STAIAD26', 'STAIAD27', 'STAIAD30',\n",
    "                        'STAIAD33', 'STAIAD34', 'STAIAD36', 'STAIAD39', 'STAIAD40']\n",
    "for col in reverse_scored_items:\n",
    "    df[col] = 5 - df[col]\n",
    "\n",
    "# Compute STAI scores\n",
    "df['STAI_State_Anxiety'] = df[state_items].sum(axis=1)\n",
    "df['STAI_Trait_Anxiety'] = df[trait_items].sum(axis=1)\n",
    "\n",
    "# GDS scoring\n",
    "gds_columns = ['GDSAFRAD', 'GDSALIVE', 'GDSBETER', 'GDSBORED', 'GDSDROPD',\n",
    "               'GDSEMPTY', 'GDSENRGY', 'GDSGSPIR', 'GDSHAPPY', 'GDSHLPLS',\n",
    "               'GDSHOME', 'GDSHOPLS', 'GDSMEMRY', 'GDSSATIS', 'GDSWRTLS']\n",
    "gds_reverse_scored_items = ['GDSAFRAD', 'GDSHAPPY', 'GDSSATIS']\n",
    "for col in gds_reverse_scored_items:\n",
    "    df[col] = 1 - df[col]\n",
    "df['GDS_Total_Score'] = df[gds_columns].sum(axis=1)\n",
    "\n",
    "# Filter visits and select columns\n",
    "required_visits = [\"V04\", \"V06\", \"V08\"]\n",
    "cog_cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\", \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"GDS_Total_Score\", \"MSEADLG\"]\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + cog_cols + [\"EVENT_ID\"]\n",
    "df = df[df[\"EVENT_ID\"].isin(required_visits)][selected_columns]\n",
    "\n",
    "# Subset cohorts\n",
    "df_control = df[df[\"COHORT\"] == \"Healthy Control\"]\n",
    "df_prod_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])]\n",
    "\n",
    "# Drop patients with missing values and incomplete visits\n",
    "def is_patient_valid(group):\n",
    "    return (len(group) == 3) and (not group[cog_cols].isnull().any().any())\n",
    "df_control = df_control.groupby(\"PATNO\").filter(is_patient_valid)\n",
    "df_prod_pd = df_prod_pd.groupby(\"PATNO\").filter(is_patient_valid)\n",
    "\n",
    "# Select cognitive features\n",
    "features = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\", \"AGE_AT_VISIT\", \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"GDS_Total_Score\", \"MSEADLG\"]\n",
    "df_control_selected = df_control[features]\n",
    "df_pd_prod_selected = df_prod_pd[features]\n",
    "\n",
    "# Z-score transformation using control group\n",
    "mean_control = np.mean(df_control_selected, axis=0)\n",
    "std_control = np.std(df_control_selected, axis=0)\n",
    "data = (df_pd_prod_selected - mean_control) / std_control\n",
    "data_control = (df_control_selected - mean_control) / std_control\n",
    "\n",
    "# Invert specific columns where higher is better (e.g., functional ability)\n",
    "columns_to_invert = [\"MSEADLG\"]\n",
    "data[columns_to_invert] = data[columns_to_invert] * -1\n",
    "\n",
    "# Drop unused columns BEFORE removing rows with negative values\n",
    "data = data.drop(columns=[\"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"MCATOT\"])\n",
    "\n",
    "# Remove patients (rows) that have any negative values\n",
    "data = data[(data >= 0).all(axis=1)]\n",
    "\n",
    "# Set SuStaIn parameters\n",
    "Z_vals = np.array([\n",
    "    [0, 1, 2, 4, 7, 0],\n",
    "    [0, 1, 4, 11, 18, 22],\n",
    "    [0, 1, 4, 8, 12, 14],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 4, 7, 0, 0],\n",
    "    [0, 3, 7, 15, 0, 0]\n",
    "])\n",
    "Z_max = np.array([23, 62, 24, 3, 13, 64])\n",
    "SuStaInLabels = data.columns.tolist()\n",
    "data_np = data.to_numpy()\n",
    "\n",
    "# Initialize SuStaIn model\n",
    "N_startpoints = 25\n",
    "N_S_max = 6\n",
    "N_iterations_MCMC = int(1e4)\n",
    "output_folder = os.path.join(os.getcwd(), 'sim')\n",
    "dataset_name = 'ppmi'\n",
    "\n",
    "sustain_input = pySuStaIn.ZscoreSustain(\n",
    "    data_np,\n",
    "    Z_vals,\n",
    "    Z_max,\n",
    "    SuStaInLabels,\n",
    "    N_startpoints,\n",
    "    N_S_max,\n",
    "    N_iterations_MCMC,\n",
    "    output_folder,\n",
    "    dataset_name,\n",
    "    False\n",
    ")\n",
    "\n",
    "# Run SuStaIn algorithm\n",
    "(samples_sequence, samples_f, ml_subtype, prob_ml_subtype,\n",
    " ml_stage, prob_ml_stage, prob_subtype_stage) = sustain_input.run_sustain_algorithm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b08c4-5286-4ba6-af34-761a428b8af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Combine control and PD/prodromal data\n",
    "combined_data = pd.concat([data_control, data], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create ground truth labels (0 = control, 1 = PD)\n",
    "gt_stages = np.concatenate([\n",
    "    np.zeros(data_control.shape[0], dtype=int),\n",
    "    np.ones(data.shape[0], dtype=int)\n",
    "])\n",
    "\n",
    "# Step 3: Create stratification labels\n",
    "labels = gt_stages.copy()\n",
    "\n",
    "# Step 4: Stratified folds\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_it = cv.split(combined_data, labels)\n",
    "\n",
    "# Step 5: Collect test indices from combined data\n",
    "offset = data_control.shape[0]\n",
    "test_idxs_combined = []\n",
    "for _, test_idx in cv_it:\n",
    "    # Adjust test indices to align with only PD data\n",
    "    fold_indices_in_data = test_idx[test_idx >= offset] - offset\n",
    "    test_idxs_combined.append(fold_indices_in_data)\n",
    "\n",
    "# Step 6: Manually test 1–6 subtypes by adjusting n_S_max\n",
    "CVIC_list = []\n",
    "loglike_matrix_list = []\n",
    "\n",
    "for n_subtypes in range(1, 7):\n",
    "    print(f\"\\n=== Testing {n_subtypes} subtype(s) ===\")\n",
    "    \n",
    "    # Set max number of subtypes in sustain_input\n",
    "    sustain_input.n_S_max = n_subtypes\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    CVIC, loglike_matrix = sustain_input.cross_validate_sustain_model(test_idxs_combined)\n",
    "    \n",
    "    # Store results\n",
    "    CVIC_list.append(CVIC[n_subtypes - 1])  # get value for the current number of subtypes\n",
    "    loglike_matrix_list.append(loglike_matrix[:, n_subtypes - 1])\n",
    "\n",
    "# Step 7: Convert results to NumPy arrays\n",
    "CVIC_array = np.array(CVIC_list)\n",
    "loglike_matrix_all = np.vstack(loglike_matrix_list).T  # shape: (n_folds, n_subtypes)\n",
    "\n",
    "# Step 8: Plot CVIC\n",
    "plt.plot(np.arange(1, 7), CVIC_array, marker='o')\n",
    "plt.xlabel(\"Number of Subtypes\")\n",
    "plt.ylabel(\"CVIC (lower is better)\")\n",
    "plt.title(\"SuStaIn Model Selection via CVIC\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final output\n",
    "print(\"Final CVIC values for subtypes 1–6:\", CVIC_array)\n",
    "print(\"Final log-likelihood matrix shape:\", loglike_matrix_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627b5ab-1f08-49e7-9f3c-21a15eaa56cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SuStaInLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053c29b-ee3f-4a8e-b835-6e7f3348d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\",\"STAI_State_Anxiety\",\"STAI_State_Anxiety\",\"GDS_Total_Score\",\"MSEADLG\"]\n",
    "\n",
    "for col in cols:\n",
    "    df_mean = df_prod_pd.groupby('EVENT_ID', as_index=False)[col].mean()\n",
    "    \n",
    "    sns.lineplot(data=df_mean, x='EVENT_ID', y=col)\n",
    "    plt.title(f\"Average {col} Across Visits\")\n",
    "    plt.xlabel(\"Visit (EVENT_ID)\")\n",
    "    plt.ylabel(f\"Average {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30f12a-1168-4bd6-a9d0-b4fa88d5e2af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\",\"STAI_State_Anxiety\",\"STAI_State_Anxiety\",\"GDS_Total_Score\",\"MSEADLG\"]\n",
    "\n",
    "for col in cols:\n",
    "    df_mean = df_control.groupby('EVENT_ID', as_index=False)[col].mean()\n",
    "    \n",
    "    sns.lineplot(data=df_mean, x='EVENT_ID', y=col)\n",
    "    plt.title(f\"Average {col} Across Visits\")\n",
    "    plt.xlabel(\"Visit (EVENT_ID)\")\n",
    "    plt.ylabel(f\"Average {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1752eb9-3692-430f-8a8c-63514b02fe09",
   "metadata": {},
   "source": [
    "# We think we will proceed with the modelling the monotnous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9bce3f-941c-4fd4-b8c0-b646ccdb7357",
   "metadata": {},
   "source": [
    "### Multiply -1 decreasing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46acfc6e-6cd4-4f09-9cbc-3f00910d87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8132b71-5688-4ee7-9136-1aab94c59571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_median_zscores(data):\n",
    "    \"\"\"\n",
    "    Plots median and IQR for each biomarker in z-scored data.\n",
    "    \"\"\"\n",
    "    if isinstance(data, np.ndarray):\n",
    "        data = pd.DataFrame(data, columns=[f\"Biomarker {i+1}\" for i in range(data.shape[1])])\n",
    "\n",
    "    medians = data.median()\n",
    "    q25 = data.quantile(0.1)\n",
    "    q75 = data.quantile(0.99)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(medians.index, medians.values, marker='o', label='Median z-score')\n",
    "    plt.fill_between(medians.index, q25, q75, alpha=0.2, label='IQR (1–99%)')\n",
    "\n",
    "    plt.axhline(1, color='gray', linestyle='--', label='Z=1')\n",
    "    plt.axhline(2, color='gray', linestyle='--', label='Z=2')\n",
    "    plt.axhline(3, color='gray', linestyle='--', label='Z=3')\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(\"Z-score\")\n",
    "    plt.title(\"Median Z-scores with IQR per Biomarker\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4549e7-9287-45e5-b90c-85ce866677f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_median_zscores(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc3b83-72db-4edc-99b0-a096fb501f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=[\"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\",\"MCATOT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f6c73-23c5-42eb-b76c-8ea23f4d28a7",
   "metadata": {},
   "source": [
    "### Z_vals is an important parameter to work with SustaIn so we need a medical researcher to assess this parameter : Z_vals are the value that calculates the transition from stage 1 to stage 2 for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15985f0c-099b-4471-9126-80920ba8fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "data[data < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b05730-4be7-4078-8e97-5f4e85c02fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired percentiles\n",
    "percentiles = [0.1, 0.25, 0.5, 0.75, 0.90,0.95]\n",
    "\n",
    "# Calculate and print percentiles for each column\n",
    "for col in data.columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    values = data[col].quantile(percentiles)\n",
    "    for p, v in zip(percentiles, values):\n",
    "        print(f\"  {int(p*100)}th percentile: {v:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381dc4f-e5f5-4fbd-8793-ea49378a3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "# output_folder = os.path.join(os.getcwd(), 'sim2')    \n",
    "# dataset_name = 'sim2' \n",
    "# sustain_input = ZscoreSustain(data,\n",
    "#                               Z_vals,\n",
    "#                               Z_max,\n",
    "#                               SuStaInLabels,\n",
    "#                               N_startpoints,\n",
    "#                               N_S_max, \n",
    "#                               N_iterations_MCMC, \n",
    "#                               output_folder, \n",
    "#                               dataset_name, \n",
    "#                               False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7657b315-a567-4d85-b50e-eb425fde4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1907b-a4d9-40b3-93a5-69dd3ff43bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c37c76-ab40-4d1b-9ecd-a9810182246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M= len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be5d7c-4aa9-4f17-8ccd-a0faa78ad681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pySuStaIn import ZscoreSustain\n",
    "\n",
    "# 1) Define your Z-score grid\n",
    "Z_vals = np.array([\n",
    "    [0, 1, 2, 4, 7, 0],\n",
    "    [0, 1, 4,11,15,15],\n",
    "    [0, 1, 4, 7,11,15],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 4, 7, 0, 0],\n",
    "    [0, 4, 7,15, 0, 0]\n",
    "])\n",
    "Z_max = np.array([23, 62, 24, 3, 13, 64])\n",
    "s=1\n",
    "# 2) Load your SuStaIn output (samples_sequence, samples_f, etc.)\n",
    "with open(output_folder + '/pickle_files/' + dataset_name + '_subtype' + str(s) + '.pickle', \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "samples_sequence = data[\"samples_sequence\"]   # shape (n_subtypes, n_events, n_samples)\n",
    "samples_f        = data[\"samples_f\"]          # shape (n_subtypes,)\n",
    "n_samples        = M         # or however you stored M\n",
    "\n",
    "# 3) Plot using the static method, passing Z_vals by name\n",
    "figs, axs = ZscoreSustain.plot_positional_var(\n",
    "    samples_sequence=samples_sequence,\n",
    "    samples_f=samples_f,\n",
    "    n_samples=n_samples,\n",
    "    Z_vals=Z_vals,\n",
    "    subtype_order=(0, 1),      # or whatever order you prefer\n",
    "    biomarker_labels=None,     # you can supply your own labels here\n",
    "    stage_label=\"SuStaIn Stage\",\n",
    "    title_font_size=12,\n",
    "    stage_font_size=10,\n",
    "    label_font_size=10,\n",
    "    stage_interval=1,\n",
    "    cmap=\"original\",\n",
    "    figsize=(10, 4)\n",
    ")\n",
    "\n",
    "# 4) Add a suptitle and show\n",
    "plt.suptitle(\"Figure 10: SuStaIn output\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7acf21-e09a-4b51-a15f-db9998ac86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pySuStaIn import ZscoreSustain\n",
    "\n",
    "# 1) Define your Z-score grid\n",
    "Z_vals = np.array([\n",
    "    [0, 1, 2, 4, 7, 0],\n",
    "    [0, 1, 4,11,15,15],\n",
    "    [0, 1, 4, 7,11,15],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 4, 7, 0, 0],\n",
    "    [0, 4, 7,15, 0, 0]\n",
    "])\n",
    "Z_max = np.array([23, 62, 24, 3, 13, 64])\n",
    "s=5\n",
    "# 2) Load your SuStaIn output (samples_sequence, samples_f, etc.)\n",
    "with open(output_folder + '/pickle_files/' + dataset_name + '_subtype' + str(s) + '.pickle', \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "samples_sequence = data[\"samples_sequence\"]   # shape (n_subtypes, n_events, n_samples)\n",
    "samples_f        = data[\"samples_f\"]          # shape (n_subtypes,)\n",
    "n_samples        = M         # or however you stored M\n",
    "\n",
    "# 3) Plot using the static method, passing Z_vals by name\n",
    "figs, axs = ZscoreSustain.plot_positional_var(\n",
    "    samples_sequence=samples_sequence,\n",
    "    samples_f=samples_f,\n",
    "    n_samples=n_samples,\n",
    "    Z_vals=Z_vals,\n",
    "    subtype_order=tuple(range(6)),      # or whatever order you prefer\n",
    "    biomarker_labels=None,     # you can supply your own labels here\n",
    "    stage_label=\"SuStaIn Stage\",\n",
    "    title_font_size=12,\n",
    "    stage_font_size=10,\n",
    "    label_font_size=10,\n",
    "    stage_interval=1,\n",
    "    cmap=\"original\",\n",
    "    figsize=(10, 4)\n",
    ")\n",
    "\n",
    "# 4) Add a suptitle and show\n",
    "plt.suptitle(\"Figure 10: SuStaIn output\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c9bb4-a069-4a7d-acab-8d0629e25e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pySuStaIn\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv', sep=';')\n",
    "\n",
    "# Define STAI items\n",
    "state_items = [f'STAIAD{i}' for i in range(1, 21)]\n",
    "trait_items = [f'STAIAD{i}' for i in range(21, 41)]\n",
    "reverse_scored_items = ['STAIAD1', 'STAIAD2', 'STAIAD5', 'STAIAD8', 'STAIAD10',\n",
    "                        'STAIAD11', 'STAIAD15', 'STAIAD16', 'STAIAD19', 'STAIAD20',\n",
    "                        'STAIAD21', 'STAIAD23', 'STAIAD26', 'STAIAD27', 'STAIAD30',\n",
    "                        'STAIAD33', 'STAIAD34', 'STAIAD36', 'STAIAD39', 'STAIAD40']\n",
    "for col in reverse_scored_items:\n",
    "    df[col] = 5 - df[col]\n",
    "\n",
    "# Compute STAI scores\n",
    "df['STAI_State_Anxiety'] = df[state_items].sum(axis=1)\n",
    "df['STAI_Trait_Anxiety'] = df[trait_items].sum(axis=1)\n",
    "\n",
    "# GDS scoring\n",
    "gds_columns = ['GDSAFRAD', 'GDSALIVE', 'GDSBETER', 'GDSBORED', 'GDSDROPD',\n",
    "               'GDSEMPTY', 'GDSENRGY', 'GDSGSPIR', 'GDSHAPPY', 'GDSHLPLS',\n",
    "               'GDSHOME', 'GDSHOPLS', 'GDSMEMRY', 'GDSSATIS', 'GDSWRTLS']\n",
    "gds_reverse_scored_items = ['GDSAFRAD', 'GDSHAPPY', 'GDSSATIS']\n",
    "for col in gds_reverse_scored_items:\n",
    "    df[col] = 1 - df[col]\n",
    "df['GDS_Total_Score'] = df[gds_columns].sum(axis=1)\n",
    "\n",
    "# Filter visits and select columns\n",
    "required_visits = [\"V04\", \"V06\", \"V08\"]\n",
    "cog_cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\", \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"GDS_Total_Score\", \"MSEADLG\"]\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + cog_cols + [\"EVENT_ID\"]\n",
    "df = df[df[\"EVENT_ID\"].isin(required_visits)][selected_columns]\n",
    "\n",
    "# Subset cohorts\n",
    "df_control = df[df[\"COHORT\"] == \"Healthy Control\"]\n",
    "df_prod_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])]\n",
    "\n",
    "# Drop patients with missing values and incomplete visits\n",
    "def is_patient_valid(group):\n",
    "    return (len(group) == 3) and (not group[cog_cols].isnull().any().any())\n",
    "df_control = df_control.groupby(\"PATNO\").filter(is_patient_valid)\n",
    "df_prod_pd = df_prod_pd.groupby(\"PATNO\").filter(is_patient_valid)\n",
    "\n",
    "# Select cognitive features\n",
    "features = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\", \"AGE_AT_VISIT\", \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"GDS_Total_Score\", \"MSEADLG\"]\n",
    "df_control_selected = df_control[features]\n",
    "df_pd_prod_selected = df_prod_pd[features]\n",
    "\n",
    "# Z-score transformation using control group\n",
    "mean_control = np.mean(df_control_selected, axis=0)\n",
    "std_control = np.std(df_control_selected, axis=0)\n",
    "data = (df_pd_prod_selected - mean_control) / std_control\n",
    "data_control = (df_control_selected - mean_control) / std_control\n",
    "\n",
    "# Invert specific columns where higher is better (e.g., functional ability)\n",
    "columns_to_invert = [\"MSEADLG\"]\n",
    "data[columns_to_invert] = data[columns_to_invert] * -1\n",
    "\n",
    "# Drop unused columns BEFORE removing rows with negative values\n",
    "data = data.drop(columns=[\"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"MCATOT\"])\n",
    "\n",
    "# Remove patients (rows) that have any negative values\n",
    "data = data[(data >= 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd008c1-25fe-46cb-97fd-c6935601fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_control = data_control.drop(columns=[\"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"MCATOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d237cc7-8686-49e5-8b75-eb10c4f32700",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5313408-e0bd-4ac6-84df-a24737d8aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a36f4-5be2-4071-a6eb-684cd251f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([data_control, data], axis=0).reset_index(drop=True)\n",
    "\n",
    "gt_stages = np.concatenate([\n",
    "    np.zeros(data_control.shape[0], dtype=int),  # Healthy controls\n",
    "    np.ones(data.shape[0], dtype=int)            # PD/prodromal\n",
    "])\n",
    "\n",
    "M = combined_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d155dd4-9692-4751-8771-149ea7af5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Concatenate control and disease data\n",
    "combined_data = pd.concat([data_control, data], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Ground truth labels: 0 for control, 1 for PD/prodromal\n",
    "gt_stages = np.concatenate([\n",
    "    np.zeros(data_control.shape[0], dtype=int),  # Controls\n",
    "    np.ones(data.shape[0], dtype=int)            # PD/prodromal\n",
    "])\n",
    "\n",
    "# Total number of samples\n",
    "M = combined_data.shape[0]\n",
    "\n",
    "# Identify control samples\n",
    "index_control = gt_stages == 0\n",
    "\n",
    "# Labels for stratified cross-validation\n",
    "labels = np.ones(M, dtype=int)\n",
    "labels[index_control] = 0\n",
    "\n",
    "# Set number of folds\n",
    "N_folds = 3\n",
    "\n",
    "# Create StratifiedKFold object\n",
    "cv = StratifiedKFold(n_splits=N_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Generate stratified folds using combined data and labels\n",
    "cv_it = cv.split(combined_data, labels)\n",
    "\n",
    "# Store test indices for each fold as a list of arrays\n",
    "test_idxs = []\n",
    "for train, test in cv_it:\n",
    "    test_idxs.append(test)\n",
    "\n",
    "# Example: Access test indices from fold 0\n",
    "print(\"Fold 0 test indices:\", test_idxs[0])\n",
    "# perform cross-validation and output the cross-validation information criterion and\n",
    "# log-likelihood on the test set for each subtypes model and fold combination\n",
    "CVIC, loglike_matrix     = sustain_input.cross_validate_sustain_model(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21472f3-0dde-425d-80f4-79b484975bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Combine control and PD/prodromal data\n",
    "combined_data = pd.concat([data_control, data], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create ground truth labels (0 = control, 1 = PD)\n",
    "gt_stages = np.concatenate([\n",
    "    np.zeros(data_control.shape[0], dtype=int),\n",
    "    np.ones(data.shape[0], dtype=int)\n",
    "])\n",
    "\n",
    "# Step 3: Create stratification labels\n",
    "labels = gt_stages.copy()\n",
    "\n",
    "# Step 4: Stratified folds\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_it = cv.split(combined_data, labels)\n",
    "\n",
    "# Step 5: Collect test indices from combined data\n",
    "offset = data_control.shape[0]\n",
    "test_idxs_combined = []\n",
    "for _, test_idx in cv_it:\n",
    "    # Adjust test indices to align with only PD data\n",
    "    fold_indices_in_data = test_idx[test_idx >= offset] - offset\n",
    "    test_idxs_combined.append(fold_indices_in_data)\n",
    "\n",
    "# Step 6: Manually test 1–6 subtypes by adjusting n_S_max\n",
    "CVIC_list = []\n",
    "loglike_matrix_list = []\n",
    "\n",
    "for n_subtypes in range(1, 7):\n",
    "    print(f\"\\n=== Testing {n_subtypes} subtype(s) ===\")\n",
    "    \n",
    "    # Set max number of subtypes in sustain_input\n",
    "    sustain_input.n_S_max = n_subtypes\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    CVIC, loglike_matrix = sustain_input.cross_validate_sustain_model(test_idxs_combined)\n",
    "    \n",
    "    # Store results\n",
    "    CVIC_list.append(CVIC[n_subtypes - 1])  # get value for the current number of subtypes\n",
    "    loglike_matrix_list.append(loglike_matrix[:, n_subtypes - 1])\n",
    "\n",
    "# Step 7: Convert results to NumPy arrays\n",
    "CVIC_array = np.array(CVIC_list)\n",
    "loglike_matrix_all = np.vstack(loglike_matrix_list).T  # shape: (n_folds, n_subtypes)\n",
    "\n",
    "# Step 8: Plot CVIC\n",
    "plt.plot(np.arange(1, 7), CVIC_array, marker='o')\n",
    "plt.xlabel(\"Number of Subtypes\")\n",
    "plt.ylabel(\"CVIC (lower is better)\")\n",
    "plt.title(\"SuStaIn Model Selection via CVIC\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final output\n",
    "print(\"Final CVIC values for subtypes 1–6:\", CVIC_array)\n",
    "print(\"Final log-likelihood matrix shape:\", loglike_matrix_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c4d1d-c6ad-4cf6-8b49-d3d947a0ab60",
   "metadata": {},
   "source": [
    "# We also will divide modelling [V04 - V06], [V06 - V08] to keep certain variables because they was affected after medication that was given at V04\n",
    "#### the variables are : \"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\",\"MCATOT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b2460-ef62-471d-9bbb-6ef366399fb0",
   "metadata": {},
   "source": [
    "# After Adding Feat valuable columns because they have higher imputation values and they will affect the dataset negatively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb759606-2850-46bc-b0df-36dc57404341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables to add are : MSEADLG, Gds Score (calculated by sum),Epworth_Sleepiness_Scale_06Jan2025\n",
    "#We can't add Hoehn and Yahr because its ordinal\n",
    "#I couldn't find LARS score\n",
    "# Define domain-specific groups\n",
    "cognitive_psychiatric = [\n",
    "    'FEATAPATHY', 'FEATDEPRES', 'FEATDELHAL',\n",
    "    'FEATCOGFLC', 'FEATCLRLEV', 'FEATPST3YR'\n",
    "]\n",
    "\n",
    "motor = [\n",
    "    'FEATDCRARM', 'FEATMTRFLC', 'FEATMCRGRA', 'FEATSHGAIT', 'FEATSTPPOS', 'FEATWDGAIT',\n",
    "    'FEATDYSART', 'FEATDYSPHG', 'FEATDYSKIN', 'FEATDYSTNA', 'FEATLMBAPX', 'FEATMYCLNS'\n",
    "]\n",
    "\n",
    "autonomic = [\n",
    "    'FEATBWLDYS', 'FEATURNDYS', 'FEATPOSHYP', 'FEATSEXDYS'\n",
    "]\n",
    "\n",
    "sensory_perceptual = [\n",
    "    'FEATCRTSNS', 'FEATDIMOLF', 'FEATNEURSS'\n",
    "]\n",
    "\n",
    "eye_brainstem = [\n",
    "    'FEATGZEPAL'\n",
    "]\n",
    "\n",
    "biological_markers = [\n",
    "    'FEATSUGRBD', 'FEATNOLEVO', 'FEATPYRTCT', 'FEATSBDERM', 'FEATINSPST'\n",
    "]\n",
    "\n",
    "# Compute domain-level scores\n",
    "df['Score_Cognitive_Psychiatric'] = df[cognitive_psychiatric].sum(axis=1)\n",
    "df['Score_Motor'] = df[motor].sum(axis=1)\n",
    "df['Score_Autonomic'] = df[autonomic].sum(axis=1)\n",
    "df['Score_Sensory_Perceptual'] = df[sensory_perceptual].sum(axis=1)\n",
    "df['Score_Eye_Brainstem'] = df[eye_brainstem].sum(axis=1)\n",
    "df['Score_Biological_Markers'] = df[biological_markers].sum(axis=1)\n",
    "\n",
    "# Optionally, compute a total combined score\n",
    "all_features = (\n",
    "    cognitive_psychiatric + motor + autonomic +\n",
    "    sensory_perceptual + eye_brainstem + biological_markers\n",
    ")\n",
    "df['Total_Symptom_Burden'] = df[all_features].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a41403-5c73-4d28-a3ab-623072558043",
   "metadata": {},
   "source": [
    "# We also will divide modelling [V04 - V06], [V06 - V08] to keep certain variables because they was affected after medication that was given at V04\n",
    "#### the variables are : \"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\",\"MCATOT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c79e9-8baa-4c15-b86c-424061867562",
   "metadata": {},
   "source": [
    "# After Selection MOCATOT And AGE_AT_VISIT valid intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a64873-2d23-443a-8617-783eb38cdd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cdfb7-5c56-4d75-855a-c32f0707b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0665375-97fc-45cc-8e60-868ec9f1a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Anxiety items (1–20)\n",
    "state_items = [\n",
    "    'STAIAD1', 'STAIAD2', 'STAIAD3', 'STAIAD4', 'STAIAD5',\n",
    "    'STAIAD6', 'STAIAD7', 'STAIAD8', 'STAIAD9', 'STAIAD10',\n",
    "    'STAIAD11', 'STAIAD12', 'STAIAD13', 'STAIAD14', 'STAIAD15',\n",
    "    'STAIAD16', 'STAIAD17', 'STAIAD18', 'STAIAD19', 'STAIAD20'\n",
    "]\n",
    "\n",
    "# Trait Anxiety items (21–40)\n",
    "trait_items = [\n",
    "    'STAIAD21', 'STAIAD22', 'STAIAD23', 'STAIAD24', 'STAIAD25',\n",
    "    'STAIAD26', 'STAIAD27', 'STAIAD28', 'STAIAD29', 'STAIAD30',\n",
    "    'STAIAD31', 'STAIAD32', 'STAIAD33', 'STAIAD34', 'STAIAD35',\n",
    "    'STAIAD36', 'STAIAD37', 'STAIAD38', 'STAIAD39', 'STAIAD40'\n",
    "]\n",
    "\n",
    "# Reverse scored items across both subscales\n",
    "reverse_scored_items = [\n",
    "    # State\n",
    "    'STAIAD1', 'STAIAD2', 'STAIAD5', 'STAIAD8', 'STAIAD10',\n",
    "    'STAIAD11', 'STAIAD15', 'STAIAD16', 'STAIAD19', 'STAIAD20',\n",
    "    # Trait\n",
    "    'STAIAD21', 'STAIAD23', 'STAIAD26', 'STAIAD27', 'STAIAD30',\n",
    "    'STAIAD33', 'STAIAD34', 'STAIAD36', 'STAIAD39', 'STAIAD40'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554930a8-6569-47a0-9867-666b455b47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse score: assuming 4-point Likert scale\n",
    "for col in reverse_scored_items:\n",
    "    df[col] = 5 - df[col]\n",
    "\n",
    "# Sum scores\n",
    "df['STAI_State_Anxiety'] = df[state_items].sum(axis=1)\n",
    "df['STAI_Trait_Anxiety'] = df[trait_items].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73098d7c-d603-4d8e-bb62-e8db65956864",
   "metadata": {},
   "outputs": [],
   "source": [
    "gds_columns = [\n",
    "    'GDSAFRAD', 'GDSALIVE', 'GDSBETER', 'GDSBORED', 'GDSDROPD',\n",
    "    'GDSEMPTY', 'GDSENRGY', 'GDSGSPIR', 'GDSHAPPY', 'GDSHLPLS',\n",
    "    'GDSHOME', 'GDSHOPLS', 'GDSMEMRY', 'GDSSATIS', 'GDSWRTLS'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6aebd0-f602-41a4-b86f-35cff4b1cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gds_reverse_scored_items = [\n",
    "    'GDSAFRAD',  # Are you basically satisfied with your life?\n",
    "    'GDSHAPPY',  # Do you feel happy most of the time?\n",
    "    'GDSSATIS'   # Do you feel that your life is worthwhile?\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b54c9a-502a-483f-a9c5-ce5cf6130262",
   "metadata": {},
   "outputs": [],
   "source": [
    "gds_regular_items = list(set(gds_columns) - set(gds_reverse_scored_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75013cf1-45a2-46fa-9ede-5730e44f3f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-score: Yes(1) becomes 0, No(0) becomes 1\n",
    "for col in gds_reverse_scored_items:\n",
    "    df[col] = 1 - df[col]\n",
    "\n",
    "# Total GDS depression score\n",
    "df['GDS_Total_Score'] = df[gds_columns].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc3f23-1640-435c-a7d1-b370ad661efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_visits = [\"V04\", \"V06\"]\n",
    "cog_cols = [\"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\",\"GDS_Total_Score\",\"MSEADLG\",\"MCATOT\",\"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\"]\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + cog_cols + [\"EVENT_ID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab9f08-3496-4f56-aa8b-b9d0ac65fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"EVENT_ID\"].isin(required_visits)][selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a3d2d-e7ca-4fcc-8cc0-c6de932e23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821b4c6-35a6-4306-ac36-99c0afb387b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16787b94-607b-46c5-a162-c37e9a32ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_pd.to_csv('./unamed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275cff8e-887d-4fb1-929e-82e28d4a3047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = df[df[\"COHORT\"].isin([\"Healthy Control\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99acac-54f0-47ab-b3f6-d615e8b1504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_selected=  df_control[[\"PATNO\",\"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\",\"GDS_Total_Score\",\"MSEADLG\",\"MCATOT\",\"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2b8c9-0a5f-4227-a271-fe478bd43ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pd_prod_selected=df_prod_pd[[\"PATNO\",\"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\",\"GDS_Total_Score\",\"MSEADLG\",\"MCATOT\",\"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e163c7c-0a49-4941-b368-1a4f101780d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import the python packages needed to generate simulated data for the tutorial\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import sys\n",
    "import pySuStaIn\n",
    "\n",
    "# this needs to point to wherever the sim folder inside pySuStaIn is on your computer\n",
    "#sys.path.insert(0,'/Users/alexandrayoung/Documents/Code/pySuStaIn-test/pySuStaIn/sim/')\n",
    "# if you're running the notebook from within the existing structure you can use\n",
    "sys.path.insert(0,'../sim/')\n",
    "from simfuncs import generate_random_Zscore_sustain_model, generate_data_Zscore_sustain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a1dae-3ad0-4d31-828f-caea854807b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_prod_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12cea7-b6d6-4dd3-b0ed-76525ea3540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Drop any PATNO who has missing values in any of those columns\n",
    "def is_patient_valid(group):\n",
    "    return (len(group) == 2) and (not group[cog_cols].isnull().any().any())\n",
    "\n",
    "df_control_selected = df_control_selected.groupby(\"PATNO\").filter(is_patient_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61ffbc-d8b7-4a89-9772-370905a28727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cab4d-70af-42c3-872e-17bf5ecaaf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_prod_selected = df_pd_prod_selected.groupby(\"PATNO\").filter(is_patient_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720f6e1-8056-46c5-85f0-0802590704e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9e1b8-32d0-4311-9476-2358fe5ad482",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_selected=  df_control[[\"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\",\"GDS_Total_Score\",\"MSEADLG\",\"MCATOT\",\"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062793d-a6b4-47f0-9945-b7b8639d4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd_prod_selected=df_prod_pd[[\"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\",\"GDS_Total_Score\",\"MSEADLG\",\"MCATOT\",\"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab53e0a-164d-45b4-8943-08887e8fd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data for control subjects\n",
    "\n",
    "\n",
    "# compute the mean and standard deviation of the control population\n",
    "mean_control = np.mean(df_control_selected,axis=0)\n",
    "std_control = np.std(df_control_selected,axis=0)\n",
    "\n",
    "# z-score the data\n",
    "data = (df_pd_prod_selected-mean_control)/std_control\n",
    "data_control = (df_control_selected-mean_control)/std_control\n",
    "\n",
    "# multiply data for decreasing biomarkers by -1\n",
    "#is_decreasing = np.mean(data,axis=0)<np.mean(data_control,axis=0)\n",
    "#data.loc[:, is_decreasing] = data.loc[:, is_decreasing] * -1\n",
    "\n",
    "# For data_control\n",
    "#data_control.loc[:, is_decreasing] = data_control.loc[:, is_decreasing] * -1\n",
    "\n",
    "# Check that the mean of the control population is 0\n",
    "#print('Mean of controls is ',np.mean(data_control,axis=0))\n",
    "# Check that the standard deviation of the control population is 1\n",
    "#print('Standard deviation of controls is ',np.std(data_control,axis=0))\n",
    "# Check that the mean of the whole dataset is positive\n",
    "#print('Mean of whole dataset is ',np.mean(data,axis=0))\n",
    "# Check that the standard deviation of the whole dataset is greater than 1\n",
    "#print('Standard deviation of whole dataset is ',np.std(data,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbcc73-8278-41de-b6e3-b43e5313ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be727b82-71f7-4928-8eed-00ee77a13b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns you want to multiply by -1\n",
    "columns_to_invert = [\"MSEADLG\",\"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\",\"MCATOT\"]  # ← put yours here\n",
    "\n",
    "# Multiply selected columns by -1\n",
    "data[columns_to_invert] = data[columns_to_invert] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae375b-4f27-4a16-8a26-576b54a78a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5bdcb2-1162-4c0b-bd06-62cfdb8d0367",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\"AGE_AT_VISIT\",\"GDS_Total_Score\",\"MSEADLG\",\"MCATOT\",\"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\"]\n",
    "percentiles_100 = data[cols].quantile(1)\n",
    "print(\"100th percentiles:\")\n",
    "print(percentiles_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaddcff-0a11-4b10-b603-1d189aac3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd90566-dc18-4e83-a7ff-3b1b0c74e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e881176-cc9e-4ec0-86ec-51a6814a36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6662ba-291e-4e56-b1d1-684d73fef9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "data[data < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba1825-c5c7-446d-8347-77923a2a0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired percentiles\n",
    "percentiles = [0.1, 0.25, 0.5, 0.75, 0.90,0.95]\n",
    "\n",
    "# Calculate and print percentiles for each column\n",
    "for col in data.columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    values = data[col].quantile(percentiles)\n",
    "    for p, v in zip(percentiles, values):\n",
    "        print(f\"  {int(p*100)}th percentile: {v:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acffb43a-38ef-4ce8-aa55-d99aa0f11b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCATOT                12.154452\n",
    "STAI_State_Anxiety     2.881103\n",
    "STAI_Trait_Anxiety     3.566949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042efe2d-c644-40a4-8cfd-166791fdcbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Z_vals:\", Z_vals)\n",
    "print(\"Z_max:\", Z_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca1fad-eeb5-4a54-b397-e97ab92b3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_vals = np.array([\n",
    "    [0, 1, 2, 4, 7, 0],\n",
    "    [0, 1, 4, 11, 18, 22],\n",
    "    [0, 1, 4, 8, 12, 14],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 4, 7 ,0, 0],\n",
    "    [0 ,3 ,7 ,15 ,0, 0],\n",
    "    [0, 1, 2, 0, 0, 0],\n",
    "    [0 ,1 ,2 ,0 ,0 ,0],\n",
    "    [0 ,1 ,2 ,3 ,0 ,0],\n",
    "    \n",
    "])\n",
    "Z_max = np.array([23, 62, 24,3,13,64,12,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627950a-5e40-4b79-926e-3dd90cd00e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(Z_vals > Z_max[:, None]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add45471-96c3-43f1-b782-8a32b7b4ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(Z_vals, annot=True, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bb4a6-a2ee-4839-ae6c-6ea98d721653",
   "metadata": {},
   "outputs": [],
   "source": [
    "SuStaInLabels = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123aace9-d880-4f55-b1dd-c7cc66c332ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56691d09-c1b6-4b74-b553-7f183c51cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the settings for z-score SuStaIn\n",
    "# To make the tutorial run faster I've set \n",
    "# N_startpoints = 10 and N_iterations_MCMC = int(1e4)\n",
    "# I recommend using N_startpoints = 25 and \n",
    "# N_iterations_MCMC = int(1e5) or int(1e6) in general though\n",
    "N_startpoints = 25\n",
    "N_S_max = 2\n",
    "N_iterations_MCMC = int(1e4)\n",
    "output_folder = os.path.join(os.getcwd(), 'sim')\n",
    "dataset_name = 'ppmi'\n",
    "sustain_input = pySuStaIn.ZscoreSustain(data,\n",
    "                              Z_vals,\n",
    "                              Z_max,\n",
    "                              SuStaInLabels,\n",
    "                              N_startpoints,\n",
    "                              N_S_max, \n",
    "                              N_iterations_MCMC, \n",
    "                              output_folder, \n",
    "                              dataset_name, \n",
    "                              False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096639b9-6656-4cc8-b782-42d676ce16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_vals = np.array([\n",
    "    [0, 1, 2, 4, 7, 0],\n",
    "    [0, 1, 4, 11, 18, 22],\n",
    "    [0, 1, 4, 8, 12, 14],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 4, 7 ,0, 0],\n",
    "    [0 ,3 ,7 ,15 ,0, 0],\n",
    "    [0, 1, 2, 0, 0, 0],\n",
    "    [0 ,1 ,2 ,0 ,0 ,0],\n",
    "    [0 ,1 ,2 ,3 ,0 ,0],\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ae348-941a-4768-8a51-04da8f190ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pySuStaIn\n",
    "\n",
    "# 1. Load raw data (suppress mixed‐type warning)\n",
    "df = pd.read_csv(\n",
    "    r'C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv',\n",
    "    sep=';',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# 2. Compute STAI State/Trait Anxiety\n",
    "state_items = [f'STAIAD{i}' for i in range(1,21)]\n",
    "trait_items = [f'STAIAD{i}' for i in range(21,41)]\n",
    "reverse_scored = [\n",
    "    # State\n",
    "    'STAIAD1','STAIAD2','STAIAD5','STAIAD8','STAIAD10',\n",
    "    'STAIAD11','STAIAD15','STAIAD16','STAIAD19','STAIAD20',\n",
    "    # Trait\n",
    "    'STAIAD21','STAIAD23','STAIAD26','STAIAD27','STAIAD30',\n",
    "    'STAIAD33','STAIAD34','STAIAD36','STAIAD39','STAIAD40'\n",
    "]\n",
    "for col in reverse_scored:\n",
    "    df[col] = 5 - df[col]\n",
    "df['STAI_State_Anxiety'] = df[state_items].sum(axis=1)\n",
    "df['STAI_Trait_Anxiety'] = df[trait_items].sum(axis=1)\n",
    "\n",
    "# 3. Compute GDS depression score\n",
    "gds_columns = [\n",
    "    'GDSAFRAD','GDSALIVE','GDSBETER','GDSBORED','GDSDROPD',\n",
    "    'GDSEMPTY','GDSENRGY','GDSGSPIR','GDSHAPPY','GDSHLPLS',\n",
    "    'GDSHOME','GDSHOPLS','GDSMEMRY','GDSSATIS','GDSWRTLS'\n",
    "]\n",
    "gds_reverse = ['GDSAFRAD','GDSHAPPY','GDSSATIS']\n",
    "for col in gds_reverse:\n",
    "    df[col] = 1 - df[col]\n",
    "df['GDS_Total_Score'] = df[gds_columns].sum(axis=1)\n",
    "\n",
    "# 4. Filter to visits V04 & V06, select columns\n",
    "required_visits = [\"V04\", \"V06\"]\n",
    "cog_cols = [\n",
    "    \"NP1RTOT\",\"NP2PTOT\",\"NP3TOT\",\n",
    "    \"AGE_AT_VISIT\",\"GDS_Total_Score\",\n",
    "    \"MSEADLG\",\"MCATOT\",\n",
    "    \"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\"\n",
    "]\n",
    "selected = [\"PATNO\",\"COHORT\",\"EVENT_ID\"] + cog_cols\n",
    "df = df[df.EVENT_ID.isin(required_visits)][selected]\n",
    "\n",
    "# 5. Split into patient vs. control, keep only subjects with both visits & no missing\n",
    "def valid(sub):\n",
    "    return len(sub)==2 and not sub[cog_cols].isnull().any().any()\n",
    "\n",
    "df_pat = df[df.COHORT.isin([\"PD\",\"Prodromal\"])].groupby(\"PATNO\").filter(valid)\n",
    "df_ctrl = df[df.COHORT==\"Healthy Control\"].groupby(\"PATNO\").filter(valid)\n",
    "\n",
    "# 6. Z‐score relative to controls\n",
    "arr_ctrl   = df_ctrl[cog_cols].values\n",
    "mean_ctrl  = arr_ctrl.mean(axis=0)\n",
    "std_ctrl   = arr_ctrl.std(axis=0)\n",
    "data_df    = (df_pat[cog_cols] - mean_ctrl) / std_ctrl\n",
    "data_ctrl  = (df_ctrl[cog_cols] - mean_ctrl) / std_ctrl\n",
    "\n",
    "# 7. Invert biomarkers where higher=better\n",
    "to_invert = [\"MSEADLG\",\"MCATOT\",\"STAI_State_Anxiety\",\"STAI_Trait_Anxiety\"]\n",
    "data_df[to_invert]    *= -1\n",
    "data_ctrl[to_invert]  *= -1\n",
    "\n",
    "# 8. Build numpy array for SuStaIn (FIX for your TypeError!)\n",
    "#    SuStaIn tries to do sustainData.data[:, :, None] so it must be a numpy array.\n",
    "data_mat = data_df.to_numpy()  \n",
    "\n",
    "# 9. Define SuStaIn model parameters\n",
    "Z_vals = np.array([\n",
    "    [0,1,2,4,7,0],\n",
    "    [0,1,4,11,18,22],\n",
    "    [0,1,4,8,12,14],\n",
    "    [0,1,0,0,0,0],\n",
    "    [0,1,4,7,0,0],\n",
    "    [0,3,7,15,0,0],\n",
    "    [0,1,2,0,0,0],\n",
    "    [0,1,2,0,0,0],\n",
    "    [0,1,2,3,0,0],\n",
    "])\n",
    "Z_max = np.array([23,62,24,3,13,64,12,2,3])\n",
    "SuStaInLabels = cog_cols   # must be length 9\n",
    "\n",
    "N_startpoints     = 25\n",
    "N_S_max           = 2\n",
    "N_iterations_MCMC = int(1e4)\n",
    "output_folder     = os.path.join(os.getcwd(), 'sim')\n",
    "dataset_name      = 'ppmi'\n",
    "\n",
    "# 10. Initialize and run SuStaIn\n",
    "sustain_input = pySuStaIn.ZscoreSustain(\n",
    "    data_mat,       # <-- numpy array, not DataFrame\n",
    "    Z_vals,\n",
    "    Z_max,\n",
    "    SuStaInLabels,\n",
    "    N_startpoints,\n",
    "    N_S_max,\n",
    "    N_iterations_MCMC,\n",
    "    output_folder,\n",
    "    dataset_name,\n",
    "    use_parallel_startpoints=False\n",
    ")\n",
    "\n",
    "samples_sequence, samples_f, ml_subtype, prob_ml_subtype, ml_stage, prob_ml_stage, prob_subtype_stage = \\\n",
    "    sustain_input.run_sustain_algorithm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc36b6-d8bc-4ab6-a46a-3e59ab043997",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='ppmi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2126e-3971-4d52-8784-4e0892752356",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\sim\\pickle_files\\ppmi_subtype0.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9a111-12a7-4804-aa23-f8571e98ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa88353-4b4c-4acc-97f1-ded43b42aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_vals = np.array([\n",
    "    [0,1,2,4,7,0],\n",
    "    [0,1,4,11,18,22],\n",
    "    [0,1,4,8,12,14],\n",
    "    [0,1,0,0,0,0],\n",
    "    [0,1,4,7,0,0],\n",
    "    [0,3,7,15,0,0],\n",
    "    [0,1,2,0,0,0],\n",
    "    [0,1,2,0,0,0],\n",
    "    [0,1,2,3,0,0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7f61b-c956-4815-aa88-bba3967a0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pySuStaIn.ZscoreSustain import ZscoreSustain\n",
    "\n",
    "# 1) your original 9×6 percentile‐value matrix\n",
    "Z_vals = np.array([\n",
    "    [0,1,2,4,7,0],\n",
    "    [0,1,4,11,18,22],\n",
    "    [0,1,4,8,12,14],\n",
    "    [0,1,0,0,0,0],\n",
    "    [0,1,4,7,0,0],\n",
    "    [0,3,7,15,0,0],\n",
    "    [0,1,2,0,0,0],\n",
    "    [0,1,2,0,0,0],\n",
    "    [0,1,2,3,0,0],\n",
    "])\n",
    "\n",
    "# 2) pick the 6 “representative” values by subsampling the sorted unique non-zero thresholds\n",
    "uv = np.unique(Z_vals[Z_vals>0])                # e.g. [1,2,3,4,7,8,11,12,14,15,18,22]\n",
    "idx = np.round(np.linspace(0, len(uv)-1, 6)).astype(int)\n",
    "thresh6 = uv[idx]                               # e.g. [1,3,7,12,15,22]\n",
    "\n",
    "# 3) snap every non-zero entry in Z_vals to its nearest of those 6\n",
    "Z_vals_reduced = np.where(\n",
    "    Z_vals>0,\n",
    "    thresh6[(np.abs(Z_vals[...,None] - thresh6)).argmin(axis=-1)],\n",
    "    0\n",
    ")\n",
    "\n",
    "# 4) inject just for plotting\n",
    "sustain_input.Z_vals = Z_vals_reduced\n",
    "\n",
    "# 5) now load & plot each subtype **without** forcing subtype_order\n",
    "for s in range(n_subtypes):\n",
    "    fp = pickle_folder / f\"{dataset_name}_subtype{s}.pickle\"\n",
    "    if not fp.exists(): \n",
    "        print(f\"skipping subtype {s} (no pickle)\") \n",
    "        continue\n",
    "\n",
    "    with open(fp, 'rb') as pf:\n",
    "        loaded = pickle.load(pf)\n",
    "\n",
    "    seq = loaded['samples_sequence']\n",
    "    f   = loaded['samples_f']\n",
    "\n",
    "    ZscoreSustain._plot_sustain_model(\n",
    "        sustain_input,\n",
    "        seq,\n",
    "        f,\n",
    "        M\n",
    "        # note: no subtype_order here\n",
    "    )\n",
    "    plt.suptitle(f\"Figure: SuStaIn output for subtype {s}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08ba48-3345-498d-a1e9-8d373f4647a0",
   "metadata": {},
   "source": [
    "# After Imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274cfd5f-061a-44fd-81ed-9611cda81783",
   "metadata": {},
   "source": [
    "We will perform minor imputation which is for under 10% missing variables and a major imputation for missing percentage between [20-60], and we wil proceed with what give us the best accuracy for the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb808d5a-593c-419d-97ba-32bda953d4bd",
   "metadata": {},
   "source": [
    "# Without Deleting Missing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1cad574-76d2-4870-a609-5357da8d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the python packages needed to generate simulated data for the tutorial\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import sys\n",
    "import pySuStaIn\n",
    "\n",
    "# this needs to point to wherever the sim folder inside pySuStaIn is on your computer\n",
    "#sys.path.insert(0,'/Users/alexandrayoung/Documents/Code/pySuStaIn-test/pySuStaIn/sim/')\n",
    "# if you're running the notebook from within the existing structure you can use\n",
    "sys.path.insert(0,'../sim/')\n",
    "from simfuncs import generate_random_Zscore_sustain_model, generate_data_Zscore_sustain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1648ef0-8b38-43da-a628-8fd4412bc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "# output_folder = os.path.join(os.getcwd(), 'sim2')    \n",
    "# dataset_name = 'sim2' \n",
    "# sustain_input = ZscoreSustain(data,\n",
    "#                               Z_vals,\n",
    "#                               Z_max,\n",
    "#                               SuStaInLabels,\n",
    "#                               N_startpoints,\n",
    "#                               N_S_max, \n",
    "#                               N_iterations_MCMC, \n",
    "#                               output_folder, \n",
    "#                               dataset_name, \n",
    "#                               False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac04534-28ca-46c9-905a-bf4a13412011",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806901a6-11c7-4dde-8a92-d3f393b6ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nss_1\\AppData\\Local\\Temp\\ipykernel_8260\\1632477050.py:9: DtypeWarning: Columns (4,11,12,58,112,193,202,204) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pySuStaIn\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv', sep=';')\n",
    "\n",
    "# Define STAI items\n",
    "state_items = [f'STAIAD{i}' for i in range(1, 21)]\n",
    "trait_items = [f'STAIAD{i}' for i in range(21, 41)]\n",
    "reverse_scored_items = ['STAIAD1', 'STAIAD2', 'STAIAD5', 'STAIAD8', 'STAIAD10',\n",
    "                        'STAIAD11', 'STAIAD15', 'STAIAD16', 'STAIAD19', 'STAIAD20',\n",
    "                        'STAIAD21', 'STAIAD23', 'STAIAD26', 'STAIAD27', 'STAIAD30',\n",
    "                        'STAIAD33', 'STAIAD34', 'STAIAD36', 'STAIAD39', 'STAIAD40']\n",
    "for col in reverse_scored_items:\n",
    "    df[col] = 5 - df[col]\n",
    "\n",
    "# Compute STAI scores\n",
    "df['STAI_State_Anxiety'] = df[state_items].sum(axis=1)\n",
    "df['STAI_Trait_Anxiety'] = df[trait_items].sum(axis=1)\n",
    "\n",
    "# GDS scoring\n",
    "gds_columns = ['GDSAFRAD', 'GDSALIVE', 'GDSBETER', 'GDSBORED', 'GDSDROPD',\n",
    "               'GDSEMPTY', 'GDSENRGY', 'GDSGSPIR', 'GDSHAPPY', 'GDSHLPLS',\n",
    "               'GDSHOME', 'GDSHOPLS', 'GDSMEMRY', 'GDSSATIS', 'GDSWRTLS']\n",
    "gds_reverse_scored_items = ['GDSAFRAD', 'GDSHAPPY', 'GDSSATIS']\n",
    "for col in gds_reverse_scored_items:\n",
    "    df[col] = 1 - df[col]\n",
    "df['GDS_Total_Score'] = df[gds_columns].sum(axis=1)\n",
    "\n",
    "# Filter visits and select columns\n",
    "required_visits = [\"V04\", \"V06\", \"V08\"]\n",
    "cog_cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\", \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"GDS_Total_Score\", \"MSEADLG\"]\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + cog_cols + [\"EVENT_ID\"]\n",
    "df = df[df[\"EVENT_ID\"].isin(required_visits)][selected_columns]\n",
    "\n",
    "# Subset cohorts\n",
    "df_control = df[df[\"COHORT\"] == \"Healthy Control\"]\n",
    "df_prod_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])]\n",
    "\n",
    "\n",
    "\n",
    "# Select cognitive features\n",
    "features = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\", \"AGE_AT_VISIT\", \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"GDS_Total_Score\", \"MSEADLG\"]\n",
    "df_control_selected = df_control[features]\n",
    "df_pd_prod_selected = df_prod_pd[features]\n",
    "\n",
    "# Z-score transformation using control group\n",
    "mean_control = np.mean(df_control_selected, axis=0)\n",
    "std_control = np.std(df_control_selected, axis=0)\n",
    "data = (df_pd_prod_selected - mean_control) / std_control\n",
    "data_control = (df_control_selected - mean_control) / std_control\n",
    "\n",
    "# Invert specific columns where higher is better (e.g., functional ability)\n",
    "columns_to_invert = [\"MSEADLG\"]\n",
    "data[columns_to_invert] = data[columns_to_invert] * -1\n",
    "\n",
    "# Drop unused columns BEFORE removing rows with negative values\n",
    "data = data.drop(columns=[\"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"MCATOT\"])\n",
    "\n",
    "# Remove patients (rows) that have any negative values\n",
    "data = data[(data >= 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "035f4d77-bded-4cfd-93f5-fbabf8a3a332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25934fea-7e3d-4ad1-90ec-c2f2a567d65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nss_1\\AppData\\Local\\Temp\\ipykernel_8260\\3396193857.py:9: DtypeWarning: Columns (4,11,12,58,112,193,202,204) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv', sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find pickle file: C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\sim\\pickle_files\\ppmi_subtype0.pickle. Running SuStaIn model for 0 subtype.\n",
      "Finding ML solution to 1 cluster problem\n",
      "Overall ML likelihood is -13498.799559947955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a4d0c574d74c31b36978e06271e01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8c2165d4de4dce885d3e7dcbbca0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8845a288a91416ca733e424d51316c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa3335b7f4147a09e94d21540417e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find pickle file: C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\sim\\pickle_files\\ppmi_subtype1.pickle. Running SuStaIn model for 1 subtype.\n",
      "Splitting cluster 1 of 1\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-11188.96704929]\n",
      "Overall ML likelihood is [-11188.96704929]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c785ae9f534f71b88774c0431a1420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b30353d00842808a2b9f9a83d345c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98664c5a73644708b81799c4a7988048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ae54b6fb514494b7d84ec3b007ab2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find pickle file: C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\sim\\pickle_files\\ppmi_subtype2.pickle. Running SuStaIn model for 2 subtype.\n",
      "Splitting cluster 1 of 2\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-10295.52618564]\n",
      "Splitting cluster 2 of 2\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-10154.89965403]\n",
      "Overall ML likelihood is [-10154.89965403]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190897e3d83040fb9524c20cf30e94ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c64391a7ce465ea79e5b84b6cb37c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969eeea39d534b70924524981edf2e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b2391ae25c442db7433b1556bd3905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find pickle file: C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\sim\\pickle_files\\ppmi_subtype3.pickle. Running SuStaIn model for 3 subtype.\n",
      "Splitting cluster 1 of 3\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-9490.51833151]\n",
      "Splitting cluster 2 of 3\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-9603.95628064]\n",
      "Splitting cluster 3 of 3\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-9636.79004621]\n",
      "Overall ML likelihood is [-9490.51833151]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd19df2796d4ae5858d2d5467386bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf86aa4fec54dd79068487f388f6299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01b2d97052145c4849b733e53837d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8db726eb9d3454491a2cd3a6375d8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find pickle file: C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\sim\\pickle_files\\ppmi_subtype4.pickle. Running SuStaIn model for 4 subtype.\n",
      "Splitting cluster 1 of 4\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-9083.56548775]\n",
      "Splitting cluster 2 of 4\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-9031.05283399]\n",
      "Splitting cluster 3 of 4\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-9110.6910674]\n",
      "Splitting cluster 4 of 4\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-9221.1550126]\n",
      "Overall ML likelihood is [-9031.05283399]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bc657ee08047b0a97fa7f138404641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4df2ab426141cb9c89c2ddc449b30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86e539f3d9a468d8610bc50f5b79159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899991ae2af14f599689486a5f1021cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find pickle file: C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\sim\\pickle_files\\ppmi_subtype5.pickle. Running SuStaIn model for 5 subtype.\n",
      "Splitting cluster 1 of 5\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-8771.07467821]\n",
      "Splitting cluster 2 of 5\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-8768.69326176]\n",
      "Splitting cluster 3 of 5\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-8905.00906545]\n",
      "Splitting cluster 4 of 5\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-8769.01102926]\n",
      "Splitting cluster 5 of 5\n",
      " + Resolving 2 cluster problem\n",
      " + Finding ML solution from hierarchical initialisation\n",
      "- ML likelihood is [-8807.72496098]\n",
      "Overall ML likelihood is [-8768.69326176]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f90183f498841beb4e81be6af7b6f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38af43df45646dab043f59cd8c1807f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1518701782d148d292071ebc23a46bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d7ed13190c44d298bba09c5ac541bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MCMC Iteration:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pySuStaIn\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv', sep=';')\n",
    "\n",
    "# Define STAI items\n",
    "state_items = [f'STAIAD{i}' for i in range(1, 21)]\n",
    "trait_items = [f'STAIAD{i}' for i in range(21, 41)]\n",
    "reverse_scored_items = ['STAIAD1', 'STAIAD2', 'STAIAD5', 'STAIAD8', 'STAIAD10',\n",
    "                        'STAIAD11', 'STAIAD15', 'STAIAD16', 'STAIAD19', 'STAIAD20',\n",
    "                        'STAIAD21', 'STAIAD23', 'STAIAD26', 'STAIAD27', 'STAIAD30',\n",
    "                        'STAIAD33', 'STAIAD34', 'STAIAD36', 'STAIAD39', 'STAIAD40']\n",
    "for col in reverse_scored_items:\n",
    "    df[col] = 5 - df[col]\n",
    "\n",
    "# Compute STAI scores\n",
    "df['STAI_State_Anxiety'] = df[state_items].sum(axis=1)\n",
    "df['STAI_Trait_Anxiety'] = df[trait_items].sum(axis=1)\n",
    "\n",
    "# GDS scoring\n",
    "gds_columns = ['GDSAFRAD', 'GDSALIVE', 'GDSBETER', 'GDSBORED', 'GDSDROPD',\n",
    "               'GDSEMPTY', 'GDSENRGY', 'GDSGSPIR', 'GDSHAPPY', 'GDSHLPLS',\n",
    "               'GDSHOME', 'GDSHOPLS', 'GDSMEMRY', 'GDSSATIS', 'GDSWRTLS']\n",
    "gds_reverse_scored_items = ['GDSAFRAD', 'GDSHAPPY', 'GDSSATIS']\n",
    "for col in gds_reverse_scored_items:\n",
    "    df[col] = 1 - df[col]\n",
    "df['GDS_Total_Score'] = df[gds_columns].sum(axis=1)\n",
    "\n",
    "# Filter visits and select columns\n",
    "required_visits = [\"V04\", \"V06\", \"V08\"]\n",
    "cog_cols = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\", \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"GDS_Total_Score\", \"MSEADLG\"]\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + cog_cols + [\"EVENT_ID\"]\n",
    "df = df[df[\"EVENT_ID\"].isin(required_visits)][selected_columns]\n",
    "\n",
    "# Subset cohorts\n",
    "df_control = df[df[\"COHORT\"] == \"Healthy Control\"]\n",
    "df_prod_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])]\n",
    "\n",
    "\n",
    "\n",
    "# Select cognitive features\n",
    "features = [\"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\", \"AGE_AT_VISIT\", \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"GDS_Total_Score\", \"MSEADLG\"]\n",
    "df_control_selected = df_control[features]\n",
    "df_pd_prod_selected = df_prod_pd[features]\n",
    "\n",
    "# Z-score transformation using control group\n",
    "mean_control = np.mean(df_control_selected, axis=0)\n",
    "std_control = np.std(df_control_selected, axis=0)\n",
    "data = (df_pd_prod_selected - mean_control) / std_control\n",
    "data_control = (df_control_selected - mean_control) / std_control\n",
    "\n",
    "# Invert specific columns where higher is better (e.g., functional ability)\n",
    "columns_to_invert = [\"MSEADLG\"]\n",
    "data[columns_to_invert] = data[columns_to_invert] * -1\n",
    "\n",
    "# Drop unused columns BEFORE removing rows with negative values\n",
    "data = data.drop(columns=[\"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\", \"MCATOT\"])\n",
    "\n",
    "# Remove patients (rows) that have any negative values\n",
    "data = data[(data >= 0).all(axis=1)]\n",
    "\n",
    "# Set SuStaIn parameters\n",
    "Z_vals = np.array([\n",
    "    [0, 1, 2, 4, 7, 0],\n",
    "    [0, 1, 4, 11, 18, 22],\n",
    "    [0, 1, 4, 8, 12, 14],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 4, 7, 0, 0],\n",
    "    [0, 3, 7, 15, 0, 0]\n",
    "])\n",
    "Z_max = np.array([23, 62, 24, 3, 13, 64])\n",
    "SuStaInLabels = data.columns.tolist()\n",
    "data_np = data.to_numpy()\n",
    "\n",
    "# Initialize SuStaIn model\n",
    "N_startpoints = 25\n",
    "N_S_max = 6\n",
    "N_iterations_MCMC = int(1e4)\n",
    "output_folder = os.path.join(os.getcwd(), 'sim')\n",
    "dataset_name = 'ppmi'\n",
    "\n",
    "sustain_input = pySuStaIn.ZscoreSustain(\n",
    "    data_np,\n",
    "    Z_vals,\n",
    "    Z_max,\n",
    "    SuStaInLabels,\n",
    "    N_startpoints,\n",
    "    N_S_max,\n",
    "    N_iterations_MCMC,\n",
    "    output_folder,\n",
    "    dataset_name,\n",
    "    False\n",
    ")\n",
    "\n",
    "# Run SuStaIn algorithm\n",
    "(samples_sequence, samples_f, ml_subtype, prob_ml_subtype,\n",
    " ml_stage, prob_ml_stage, prob_subtype_stage) = sustain_input.run_sustain_algorithm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089bbbab-38c6-4d62-a694-459be1882a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=len(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebbabe55-baa3-4668-959f-ff7d3d1e7462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b2a2ac-0dbe-417f-82da-2f46c284d887",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 2) Load your SuStaIn output (samples_sequence, samples_f, etc.)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43moutput_folder\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/pickle_files/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dataset_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_subtype\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     19\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     20\u001b[0m samples_sequence \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples_sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m]   \u001b[38;5;66;03m# shape (n_subtypes, n_events, n_samples)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_folder' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pySuStaIn import ZscoreSustain\n",
    "\n",
    "# 1) Define your Z-score grid\n",
    "Z_vals = np.array([\n",
    "    [0, 1, 2, 4, 7, 0],\n",
    "    [0, 1, 4,11,15,15],\n",
    "    [0, 1, 4, 7,11,15],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 4, 7, 0, 0],\n",
    "    [0, 4, 7,15, 0, 0]\n",
    "])\n",
    "Z_max = np.array([23, 62, 24, 3, 13, 64])\n",
    "s=5\n",
    "# 2) Load your SuStaIn output (samples_sequence, samples_f, etc.)\n",
    "with open(output_folder + '/pickle_files/' + dataset_name + '_subtype' + str(s) + '.pickle', \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "samples_sequence = data[\"samples_sequence\"]   # shape (n_subtypes, n_events, n_samples)\n",
    "samples_f        = data[\"samples_f\"]          # shape (n_subtypes,)\n",
    "n_samples        = M         # or however you stored M\n",
    "\n",
    "# 3) Plot using the static method, passing Z_vals by name\n",
    "figs, axs = ZscoreSustain.plot_positional_var(\n",
    "    samples_sequence=samples_sequence,\n",
    "    samples_f=samples_f,\n",
    "    n_samples=n_samples,\n",
    "    Z_vals=Z_vals,\n",
    "    subtype_order=tuple(range(6)),      # or whatever order you prefer\n",
    "    biomarker_labels=None,     # you can supply your own labels here\n",
    "    stage_label=\"SuStaIn Stage\",\n",
    "    title_font_size=12,\n",
    "    stage_font_size=10,\n",
    "    label_font_size=10,\n",
    "    stage_interval=1,\n",
    "    cmap=\"original\",\n",
    "    figsize=(10, 4)\n",
    ")\n",
    "\n",
    "# 4) Add a suptitle and show\n",
    "plt.suptitle(\"Figure 10: SuStaIn output\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
