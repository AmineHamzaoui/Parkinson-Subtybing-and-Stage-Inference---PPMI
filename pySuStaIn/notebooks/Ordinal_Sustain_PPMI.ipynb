{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0d2ba9-a6e3-4e56-b9d7-290bd2318d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0451f0be-6d4f-45a9-a229-8f8e70b44a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nss_1\\AppData\\Local\\Temp\\ipykernel_26032\\3495069841.py:1: DtypeWarning: Columns (4,11,12,58,112,193,202,204) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df= pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv',sep=';')\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ec9775-45a9-4523-bf47-3d6801bd1cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal variables (3 to 5 unique non-null values):\n",
      "['COGCAT', 'COGCAT_TEXT', 'COGDXCL', 'COGSTATE', 'COHORT', 'DBSOFFTM', 'DXLVL', 'FEATAPATHY', 'FEATBWLDYS', 'FEATCLRLEV', 'FEATCOGFLC', 'FEATCRTSNS', 'FEATDCRARM', 'FEATDELHAL', 'FEATDEPRES', 'FEATDIMOLF', 'FEATDYSART', 'FEATDYSKIN', 'FEATDYSPHG', 'FEATDYSTNA', 'FEATGZEPAL', 'FEATINSPST', 'FEATLMBAPX', 'FEATMCRGRA', 'FEATMTRFLC', 'FEATMYCLNS', 'FEATNEURSS', 'FEATNOLEVO', 'FEATPOSHYP', 'FEATPST3YR', 'FEATPYRTCT', 'FEATSBDERM', 'FEATSEXDYS', 'FEATSHGAIT', 'FEATSTPPOS', 'FEATSUGRBD', 'FEATURNDYS', 'FEATWDGAIT', 'MCAABSTR', 'MCASER7', 'MCASNTNC', 'MRIRSLT', 'NP1ANXS', 'NP1APAT', 'NP1COG', 'NP1DPRS', 'NP1HALL', 'NP2DRES', 'NP2EAT', 'NP2FREZ', 'NP2HOBB', 'NP2HWRT', 'NP2HYGN', 'NP2RISE', 'NP2SALV', 'NP2SPCH', 'NP2SWAL', 'NP2TRMR', 'NP2TURN', 'NP2WALK', 'NP3PTRML', 'NP3RTALL', 'NP3RTARL', 'NP3SPCH', 'NUPSOURC_prev', 'NUPSOURC_score2', 'OFFNORSN', 'ONNORSN', 'PTCGBOTH', 'STAIAD1', 'STAIAD10', 'STAIAD11', 'STAIAD12', 'STAIAD13', 'STAIAD14', 'STAIAD15', 'STAIAD16', 'STAIAD17', 'STAIAD18', 'STAIAD19', 'STAIAD2', 'STAIAD20', 'STAIAD21', 'STAIAD22', 'STAIAD23', 'STAIAD24', 'STAIAD25', 'STAIAD26', 'STAIAD27', 'STAIAD28', 'STAIAD29', 'STAIAD3', 'STAIAD30', 'STAIAD31', 'STAIAD32', 'STAIAD33', 'STAIAD34', 'STAIAD35', 'STAIAD36', 'STAIAD37', 'STAIAD38', 'STAIAD39', 'STAIAD4', 'STAIAD40', 'STAIAD5', 'STAIAD6', 'STAIAD7', 'STAIAD8', 'STAIAD9']\n"
     ]
    }
   ],
   "source": [
    "ordinal_vars = [\n",
    "    col for col in df.columns\n",
    "    if 3 <= df[col].dropna().nunique() <= 5\n",
    "]\n",
    "\n",
    "print(\"Ordinal variables (3 to 5 unique non-null values):\")\n",
    "print(ordinal_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67996419-dc5f-4338-8837-f2f633f53c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to try alone because they're missing value exceed 50%\n",
    "#'DXLVL'(v02,v04,v05,v06,v08)\n",
    "#FEATAPATHY V04,v05,v06,v08\n",
    "#FEATBWLDYS\n",
    "#FEATCLRLEV\n",
    "#FEATGZEPAL\tFEATINSPST\tFEATLMBAPX\tFEATMCRGRA\tFEATMTRFLC\n",
    "#FEATSHGAIT\tFEATSTPPOS\tFEATSUGRBD\n",
    "#NP Scores could be imputed over all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9097b7-b9c8-4a19-889b-3ac2dcf692be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required_visits = [\"V04\", \"V06\", \"V08\"]\n",
    "required_visits = [\"V04\"]\n",
    "ordinal_vars = ['COGCAT', 'COGDXCL', 'COGSTATE', 'FEATCOGFLC', 'FEATCRTSNS', 'FEATDCRARM', \n",
    "                'FEATDELHAL', 'FEATDEPRES', 'FEATDIMOLF', 'FEATDYSART', 'FEATDYSKIN',\n",
    "                'FEATDYSPHG', 'FEATDYSTNA', 'FEATMYCLNS',\n",
    "                'FEATNEURSS', 'FEATNOLEVO', 'FEATPOSHYP', 'FEATPST3YR', 'FEATPYRTCT', 'FEATSBDERM', \n",
    "                'FEATSEXDYS', 'FEATURNDYS', 'FEATWDGAIT', 'MCAABSTR', 'MCASER7', 'MCASNTNC', 'MRIRSLT', \n",
    "                'NP1ANXS', 'NP1APAT', 'NP1COG', 'NP1DPRS', 'NP1HALL', 'NP2DRES', 'NP2EAT', 'NP2FREZ', \n",
    "                'NP2HOBB', 'NP2HWRT', 'NP2HYGN', 'NP2RISE', 'NP2SALV', 'NP2SPCH', 'NP2SWAL', 'NP2TRMR', \n",
    "                'NP2TURN', 'NP2WALK', 'NP3PTRML', 'NP3RTALL', 'NP3RTARL', 'NP3SPCH', 'PTCGBOTH', \n",
    "                'STAIAD1', 'STAIAD10', 'STAIAD11', 'STAIAD12', 'STAIAD13', 'STAIAD14', 'STAIAD15', \n",
    "                'STAIAD16', 'STAIAD17', 'STAIAD18', 'STAIAD19', 'STAIAD2', 'STAIAD20', 'STAIAD21', \n",
    "                'STAIAD22', 'STAIAD23', 'STAIAD24', 'STAIAD25', 'STAIAD26', 'STAIAD27', 'STAIAD28', \n",
    "                'STAIAD29', 'STAIAD3', 'STAIAD30', 'STAIAD31', 'STAIAD32', 'STAIAD33', 'STAIAD34', \n",
    "                'STAIAD35', 'STAIAD36', 'STAIAD37', 'STAIAD38', 'STAIAD39', 'STAIAD4', 'STAIAD40', \n",
    "                'STAIAD5', 'STAIAD6', 'STAIAD7', 'STAIAD8', 'STAIAD9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fb347ea-c673-4569-8754-f44fd1142ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + ordinal_vars + [\"EVENT_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7a46adb-eda4-4ea1-afcd-9a5df093fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>AGE_AT_VISIT</th>\n",
       "      <th>FINAL_SEX_ENCODED</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>COGCAT</th>\n",
       "      <th>COGDXCL</th>\n",
       "      <th>COGSTATE</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>FEATCOGFLC</th>\n",
       "      <th>FEATCRTSNS</th>\n",
       "      <th>...</th>\n",
       "      <th>STAIAD38</th>\n",
       "      <th>STAIAD39</th>\n",
       "      <th>STAIAD4</th>\n",
       "      <th>STAIAD40</th>\n",
       "      <th>STAIAD5</th>\n",
       "      <th>STAIAD6</th>\n",
       "      <th>STAIAD7</th>\n",
       "      <th>STAIAD8</th>\n",
       "      <th>STAIAD9</th>\n",
       "      <th>EVENT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000</td>\n",
       "      <td>70.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Healthy Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Healthy Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3001</td>\n",
       "      <td>66.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3002</td>\n",
       "      <td>68.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3003</td>\n",
       "      <td>57.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3004</td>\n",
       "      <td>60.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Healthy Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Healthy Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12422</th>\n",
       "      <td>293740</td>\n",
       "      <td>54.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>293759</td>\n",
       "      <td>48.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12429</th>\n",
       "      <td>293787</td>\n",
       "      <td>46.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12433</th>\n",
       "      <td>293798</td>\n",
       "      <td>72.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12439</th>\n",
       "      <td>293823</td>\n",
       "      <td>62.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prodromal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Prodromal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2705 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PATNO  AGE_AT_VISIT  FINAL_SEX_ENCODED           COHORT  COGCAT  \\\n",
       "3        3000          70.2                0.0  Healthy Control     NaN   \n",
       "12       3001          66.2                1.0               PD     NaN   \n",
       "20       3002          68.7                0.0               PD     NaN   \n",
       "28       3003          57.7                0.0               PD     NaN   \n",
       "36       3004          60.4                1.0  Healthy Control     NaN   \n",
       "...       ...           ...                ...              ...     ...   \n",
       "12422  293740          54.4                NaN               PD     NaN   \n",
       "12425  293759          48.2                NaN               PD     NaN   \n",
       "12429  293787          46.4                NaN               PD     NaN   \n",
       "12433  293798          72.5                NaN               PD     NaN   \n",
       "12439  293823          62.7                NaN        Prodromal     NaN   \n",
       "\n",
       "       COGDXCL  COGSTATE           COHORT  FEATCOGFLC  FEATCRTSNS  ...  \\\n",
       "3          NaN       NaN  Healthy Control         NaN         NaN  ...   \n",
       "12         NaN       NaN               PD         NaN         NaN  ...   \n",
       "20         NaN       NaN               PD         NaN         NaN  ...   \n",
       "28         NaN       NaN               PD         NaN         NaN  ...   \n",
       "36         NaN       NaN  Healthy Control         NaN         NaN  ...   \n",
       "...        ...       ...              ...         ...         ...  ...   \n",
       "12422      1.0       1.0               PD         0.0         0.0  ...   \n",
       "12425      1.0       1.0               PD         0.0         0.0  ...   \n",
       "12429      NaN       NaN               PD         NaN         NaN  ...   \n",
       "12433      2.0       1.0               PD         0.0         0.0  ...   \n",
       "12439      1.0       1.0        Prodromal         0.0         0.0  ...   \n",
       "\n",
       "       STAIAD38  STAIAD39  STAIAD4  STAIAD40  STAIAD5  STAIAD6  STAIAD7  \\\n",
       "3           2.0       4.0      1.0       1.0      4.0      1.0      1.0   \n",
       "12          2.0       4.0      4.0       2.0      4.0      1.0      1.0   \n",
       "20          4.0       3.0      1.0       2.0      4.0      1.0      1.0   \n",
       "28          1.0       4.0      1.0       1.0      4.0      1.0      1.0   \n",
       "36          2.0       4.0      1.0       2.0      3.0      1.0      1.0   \n",
       "...         ...       ...      ...       ...      ...      ...      ...   \n",
       "12422       2.0       3.0      1.0       2.0      3.0      1.0      1.0   \n",
       "12425       1.0       3.0      1.0       1.0      3.0      1.0      2.0   \n",
       "12429       NaN       NaN      NaN       NaN      NaN      NaN      NaN   \n",
       "12433       2.0       2.0      2.0       2.0      2.0      2.0      2.0   \n",
       "12439       2.0       2.0      1.0       2.0      2.0      1.0      2.0   \n",
       "\n",
       "       STAIAD8  STAIAD9  EVENT_ID  \n",
       "3          1.0      1.0       V04  \n",
       "12         3.0      1.0       V04  \n",
       "20         4.0      1.0       V04  \n",
       "28         4.0      1.0       V04  \n",
       "36         3.0      1.0       V04  \n",
       "...        ...      ...       ...  \n",
       "12422      3.0      1.0       V04  \n",
       "12425      3.0      1.0       V04  \n",
       "12429      NaN      NaN       V04  \n",
       "12433      2.0      1.0       V04  \n",
       "12439      2.0      1.0       V04  \n",
       "\n",
       "[2705 rows x 96 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f498ed9-6ab5-4d50-987a-fd3833677e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"EVENT_ID\"].isin(required_visits)][selected_columns]\n",
    "\n",
    "# Subset cohorts\n",
    "df_control = df[df[\"COHORT\"] == \"Healthy Control\"]\n",
    "df_prod_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca92ec50-32f3-40d8-a0d8-0b24fe3b33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the python packages needed to generate simulated data for the tutorial\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import sys\n",
    "import pySuStaIn\n",
    "\n",
    "# this needs to point to wherever the sim folder inside pySuStaIn is on your computer\n",
    "#sys.path.insert(0,'/Users/alexandrayoung/Documents/Code/pySuStaIn-test/pySuStaIn/sim/')\n",
    "# if you're running the notebook from within the existing structure you can use\n",
    "sys.path.insert(0,'../sim/')\n",
    "from simfuncs import generate_random_Zscore_sustain_model, generate_data_Zscore_sustain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2635a4-a789-404e-9a81-523cc248a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = df[df[\"COHORT\"].isin([\"Healthy Control\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b01885-8124-4a6d-b9de-3f7db600715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nss_1\\AppData\\Local\\Temp\\ipykernel_25644\\3778847406.py:20: DtypeWarning: Columns (4,11,12,58,112,193,202,204) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df= pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv',sep=';')\n"
     ]
    }
   ],
   "source": [
    "# import the python packages needed to generate simulated data for the tutorial\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import sys\n",
    "import pySuStaIn\n",
    "\n",
    "# this needs to point to wherever the sim folder inside pySuStaIn is on your computer\n",
    "#sys.path.insert(0,'/Users/alexandrayoung/Documents/Code/pySuStaIn-test/pySuStaIn/sim/')\n",
    "# if you're running the notebook from within the existing structure you can use\n",
    "sys.path.insert(0,'../sim/')\n",
    "from simfuncs import generate_random_Zscore_sustain_model, generate_data_Zscore_sustain\n",
    "\n",
    "df= pd.read_csv('C:/Users/nss_1/Desktop/SustalIn/pySuStaIn/notebooks/result_4_long_format.csv',sep=';')\n",
    "#required_visits = [\"V04\", \"V06\", \"V08\"]\n",
    "required_visits = [\"V08\"]\n",
    "ordinal_vars = ['COGCAT', 'COGDXCL', 'COGSTATE', 'FEATCOGFLC', 'FEATCRTSNS', 'FEATDCRARM', \n",
    "                'FEATDELHAL', 'FEATDEPRES', 'FEATDIMOLF', 'FEATDYSART', 'FEATDYSKIN',\n",
    "                'FEATDYSPHG', 'FEATDYSTNA', 'FEATMYCLNS',\n",
    "                'FEATNEURSS', 'FEATNOLEVO', 'FEATPOSHYP', 'FEATPST3YR', 'FEATPYRTCT', 'FEATSBDERM', \n",
    "                'FEATSEXDYS', 'FEATURNDYS', 'FEATWDGAIT', 'MCAABSTR', 'MCASER7', 'MCASNTNC', 'MRIRSLT', \n",
    "                'NP1ANXS', 'NP1APAT', 'NP1COG', 'NP1DPRS', 'NP1HALL', 'NP2DRES', 'NP2EAT', 'NP2FREZ', \n",
    "                'NP2HOBB', 'NP2HWRT', 'NP2HYGN', 'NP2RISE', 'NP2SALV', 'NP2SPCH', 'NP2SWAL', 'NP2TRMR', \n",
    "                'NP2TURN', 'NP2WALK', 'NP3PTRML', 'NP3RTALL', 'NP3RTARL', 'NP3SPCH', 'PTCGBOTH', \n",
    "                'STAIAD1', 'STAIAD10', 'STAIAD11', 'STAIAD12', 'STAIAD13', 'STAIAD14', 'STAIAD15', \n",
    "                'STAIAD16', 'STAIAD17', 'STAIAD18', 'STAIAD19', 'STAIAD2', 'STAIAD20', 'STAIAD21', \n",
    "                'STAIAD22', 'STAIAD23', 'STAIAD24', 'STAIAD25', 'STAIAD26', 'STAIAD27', 'STAIAD28', \n",
    "                'STAIAD29', 'STAIAD3', 'STAIAD30', 'STAIAD31', 'STAIAD32', 'STAIAD33', 'STAIAD34', \n",
    "                'STAIAD35', 'STAIAD36', 'STAIAD37', 'STAIAD38', 'STAIAD39', 'STAIAD4', 'STAIAD40', \n",
    "                'STAIAD5', 'STAIAD6', 'STAIAD7', 'STAIAD8', 'STAIAD9']\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + ordinal_vars + [\"EVENT_ID\"]\n",
    "df = df[df[\"EVENT_ID\"].isin(required_visits)][selected_columns]\n",
    "\n",
    "# Subset cohorts\n",
    "df_control = df[df[\"COHORT\"] == \"Healthy Control\"]\n",
    "df_prod_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcc507c3-b1ce-4a2c-aa3c-7424016f8d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>AGE_AT_VISIT</th>\n",
       "      <th>FINAL_SEX_ENCODED</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>COGCAT</th>\n",
       "      <th>COGDXCL</th>\n",
       "      <th>COGSTATE</th>\n",
       "      <th>FEATCOGFLC</th>\n",
       "      <th>FEATCRTSNS</th>\n",
       "      <th>FEATDCRARM</th>\n",
       "      <th>...</th>\n",
       "      <th>STAIAD38</th>\n",
       "      <th>STAIAD39</th>\n",
       "      <th>STAIAD4</th>\n",
       "      <th>STAIAD40</th>\n",
       "      <th>STAIAD5</th>\n",
       "      <th>STAIAD6</th>\n",
       "      <th>STAIAD7</th>\n",
       "      <th>STAIAD8</th>\n",
       "      <th>STAIAD9</th>\n",
       "      <th>EVENT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3001</td>\n",
       "      <td>68.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3003</td>\n",
       "      <td>59.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3010</td>\n",
       "      <td>50.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3012</td>\n",
       "      <td>61.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3018</td>\n",
       "      <td>63.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>114526</td>\n",
       "      <td>62.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>114613</td>\n",
       "      <td>60.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prodromal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10075</th>\n",
       "      <td>114615</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10151</th>\n",
       "      <td>116531</td>\n",
       "      <td>70.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>121626</td>\n",
       "      <td>78.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1086 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PATNO  AGE_AT_VISIT  FINAL_SEX_ENCODED     COHORT  COGCAT  COGDXCL  \\\n",
       "16       3001          68.3                1.0         PD     2.0      2.0   \n",
       "31       3003          59.7                0.0         PD     2.0      2.0   \n",
       "71       3010          50.2                1.0         PD     2.0      2.0   \n",
       "85       3012          61.9                1.0         PD     2.0      2.0   \n",
       "116      3018          63.6                0.0         PD     3.0      2.0   \n",
       "...       ...           ...                ...        ...     ...      ...   \n",
       "10061  114526          62.9                NaN         PD     NaN      1.0   \n",
       "10070  114613          60.4                NaN  Prodromal     NaN      1.0   \n",
       "10075  114615          68.0                NaN         PD     NaN      1.0   \n",
       "10151  116531          70.2                NaN         PD     NaN      2.0   \n",
       "10233  121626          78.6                NaN         PD     NaN      1.0   \n",
       "\n",
       "       COGSTATE  FEATCOGFLC  FEATCRTSNS  FEATDCRARM  ...  STAIAD38  STAIAD39  \\\n",
       "16          1.0         1.0         NaN         NaN  ...       2.0       4.0   \n",
       "31          1.0         0.0         NaN         NaN  ...       1.0       3.0   \n",
       "71          1.0         0.0         NaN         NaN  ...       3.0       3.0   \n",
       "85          2.0         1.0         NaN         NaN  ...       2.0       3.0   \n",
       "116         1.0         0.0         NaN         NaN  ...       2.0       3.0   \n",
       "...         ...         ...         ...         ...  ...       ...       ...   \n",
       "10061       1.0         0.0         0.0         2.0  ...       1.0       4.0   \n",
       "10070       1.0         0.0         0.0         0.0  ...       1.0       4.0   \n",
       "10075       1.0         0.0         0.0         1.0  ...       1.0       4.0   \n",
       "10151       1.0         2.0         0.0         1.0  ...       1.0       4.0   \n",
       "10233       1.0         0.0         0.0         1.0  ...       2.0       3.0   \n",
       "\n",
       "       STAIAD4  STAIAD40  STAIAD5  STAIAD6  STAIAD7  STAIAD8  STAIAD9  \\\n",
       "16         1.0       1.0      4.0      4.0      1.0      3.0      1.0   \n",
       "31         1.0       1.0      3.0      1.0      1.0      4.0      1.0   \n",
       "71         1.0       3.0      2.0      1.0      2.0      1.0      1.0   \n",
       "85         1.0       2.0      3.0      1.0      2.0      2.0      1.0   \n",
       "116        1.0       2.0      4.0      1.0      4.0      3.0      1.0   \n",
       "...        ...       ...      ...      ...      ...      ...      ...   \n",
       "10061      1.0       1.0      3.0      1.0      1.0      3.0      1.0   \n",
       "10070      1.0       2.0      4.0      1.0      2.0      4.0      1.0   \n",
       "10075      1.0       1.0      4.0      1.0      2.0      4.0      1.0   \n",
       "10151      2.0       1.0      3.0      1.0      1.0      3.0      1.0   \n",
       "10233      2.0       1.0      3.0      1.0      1.0      3.0      3.0   \n",
       "\n",
       "       EVENT_ID  \n",
       "16          V08  \n",
       "31          V08  \n",
       "71          V08  \n",
       "85          V08  \n",
       "116         V08  \n",
       "...         ...  \n",
       "10061       V08  \n",
       "10070       V08  \n",
       "10075       V08  \n",
       "10151       V08  \n",
       "10233       V08  \n",
       "\n",
       "[1086 rows x 95 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prod_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6053212c-e17a-4e1a-984d-809186ac6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PD/Prodromal subjects at V04: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "After subsetting to EVENT_ID == 'V04' and COHORT in ['PD','Prodromal'], no rows remain.\nPlease (a) confirm that 'V04' actually appears in your CSV's EVENT_ID column, and\n(b) confirm that some rows have COHORT == 'PD' or 'Prodromal' at visit V04.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of PD/Prodromal subjects at V04:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_pd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_pd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter subsetting to EVENT_ID == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV04\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and COHORT in [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPD\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProdromal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], no rows remain.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease (a) confirm that \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV04\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m actually appears in your CSV\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms EVENT_ID column, and\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(b) confirm that some rows have COHORT == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPD\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProdromal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m at visit V04.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: After subsetting to EVENT_ID == 'V04' and COHORT in ['PD','Prodromal'], no rows remain.\nPlease (a) confirm that 'V04' actually appears in your CSV's EVENT_ID column, and\n(b) confirm that some rows have COHORT == 'PD' or 'Prodromal' at visit V04."
     ]
    }
   ],
   "source": [
    "# Immediately check how many rows survived:\n",
    "print(\"Number of PD/Prodromal subjects at V04:\", df_pd.shape[0])\n",
    "if df_pd.shape[0] == 0:\n",
    "    raise ValueError(\n",
    "        \"After subsetting to EVENT_ID == 'V04' and COHORT in ['PD','Prodromal'], no rows remain.\\n\"\n",
    "        \"Please (a) confirm that 'V04' actually appears in your CSV's EVENT_ID column, and\\n\"\n",
    "        \"(b) confirm that some rows have COHORT == 'PD' or 'Prodromal' at visit V04.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8553dd89-1e32-40f6-815f-708c0dfe0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now—before casting to int—force each ordinal variable to numeric, coercing errors → NaN\n",
    "for col in ordinal_vars:\n",
    "    # This will convert unparseable entries (e.g. strings like \"NA\" or blank) to NaN\n",
    "    df_pd[col] = pd.to_numeric(df_pd[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29c5f2e5-7813-492e-893c-6159c9ffbe7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>AGE_AT_VISIT</th>\n",
       "      <th>FINAL_SEX_ENCODED</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>COGCAT</th>\n",
       "      <th>COGDXCL</th>\n",
       "      <th>COGSTATE</th>\n",
       "      <th>FEATCOGFLC</th>\n",
       "      <th>FEATCRTSNS</th>\n",
       "      <th>FEATDCRARM</th>\n",
       "      <th>...</th>\n",
       "      <th>STAIAD38</th>\n",
       "      <th>STAIAD39</th>\n",
       "      <th>STAIAD4</th>\n",
       "      <th>STAIAD40</th>\n",
       "      <th>STAIAD5</th>\n",
       "      <th>STAIAD6</th>\n",
       "      <th>STAIAD7</th>\n",
       "      <th>STAIAD8</th>\n",
       "      <th>STAIAD9</th>\n",
       "      <th>EVENT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3001</td>\n",
       "      <td>68.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3003</td>\n",
       "      <td>59.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3010</td>\n",
       "      <td>50.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3012</td>\n",
       "      <td>61.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3018</td>\n",
       "      <td>63.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>114526</td>\n",
       "      <td>62.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>114613</td>\n",
       "      <td>60.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prodromal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10075</th>\n",
       "      <td>114615</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10151</th>\n",
       "      <td>116531</td>\n",
       "      <td>70.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>121626</td>\n",
       "      <td>78.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>V08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1086 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PATNO  AGE_AT_VISIT  FINAL_SEX_ENCODED     COHORT  COGCAT  COGDXCL  \\\n",
       "16       3001          68.3                1.0         PD     2.0      2.0   \n",
       "31       3003          59.7                0.0         PD     2.0      2.0   \n",
       "71       3010          50.2                1.0         PD     2.0      2.0   \n",
       "85       3012          61.9                1.0         PD     2.0      2.0   \n",
       "116      3018          63.6                0.0         PD     3.0      2.0   \n",
       "...       ...           ...                ...        ...     ...      ...   \n",
       "10061  114526          62.9                NaN         PD     NaN      1.0   \n",
       "10070  114613          60.4                NaN  Prodromal     NaN      1.0   \n",
       "10075  114615          68.0                NaN         PD     NaN      1.0   \n",
       "10151  116531          70.2                NaN         PD     NaN      2.0   \n",
       "10233  121626          78.6                NaN         PD     NaN      1.0   \n",
       "\n",
       "       COGSTATE  FEATCOGFLC  FEATCRTSNS  FEATDCRARM  ...  STAIAD38  STAIAD39  \\\n",
       "16          1.0         1.0         NaN         NaN  ...       2.0       4.0   \n",
       "31          1.0         0.0         NaN         NaN  ...       1.0       3.0   \n",
       "71          1.0         0.0         NaN         NaN  ...       3.0       3.0   \n",
       "85          2.0         1.0         NaN         NaN  ...       2.0       3.0   \n",
       "116         1.0         0.0         NaN         NaN  ...       2.0       3.0   \n",
       "...         ...         ...         ...         ...  ...       ...       ...   \n",
       "10061       1.0         0.0         0.0         2.0  ...       1.0       4.0   \n",
       "10070       1.0         0.0         0.0         0.0  ...       1.0       4.0   \n",
       "10075       1.0         0.0         0.0         1.0  ...       1.0       4.0   \n",
       "10151       1.0         2.0         0.0         1.0  ...       1.0       4.0   \n",
       "10233       1.0         0.0         0.0         1.0  ...       2.0       3.0   \n",
       "\n",
       "       STAIAD4  STAIAD40  STAIAD5  STAIAD6  STAIAD7  STAIAD8  STAIAD9  \\\n",
       "16         1.0       1.0      4.0      4.0      1.0      3.0      1.0   \n",
       "31         1.0       1.0      3.0      1.0      1.0      4.0      1.0   \n",
       "71         1.0       3.0      2.0      1.0      2.0      1.0      1.0   \n",
       "85         1.0       2.0      3.0      1.0      2.0      2.0      1.0   \n",
       "116        1.0       2.0      4.0      1.0      4.0      3.0      1.0   \n",
       "...        ...       ...      ...      ...      ...      ...      ...   \n",
       "10061      1.0       1.0      3.0      1.0      1.0      3.0      1.0   \n",
       "10070      1.0       2.0      4.0      1.0      2.0      4.0      1.0   \n",
       "10075      1.0       1.0      4.0      1.0      2.0      4.0      1.0   \n",
       "10151      2.0       1.0      3.0      1.0      1.0      3.0      1.0   \n",
       "10233      2.0       1.0      3.0      1.0      1.0      3.0      3.0   \n",
       "\n",
       "       EVENT_ID  \n",
       "16          V08  \n",
       "31          V08  \n",
       "71          V08  \n",
       "85          V08  \n",
       "116         V08  \n",
       "...         ...  \n",
       "10061       V08  \n",
       "10070       V08  \n",
       "10075       V08  \n",
       "10151       V08  \n",
       "10233       V08  \n",
       "\n",
       "[1086 rows x 95 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0030149-0efe-4113-8ca1-c00ffa935744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.dropna(subset=ordinal_vars, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ecab81d-4a01-4e7a-b995-89b258c2336a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1, ..., 1, 3, 1],\n",
       "       [2, 1, 0, ..., 1, 4, 1],\n",
       "       [2, 1, 0, ..., 2, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 0, ..., 2, 4, 1],\n",
       "       [2, 1, 2, ..., 1, 3, 1],\n",
       "       [1, 1, 0, ..., 1, 3, 3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c89ca13a-92d1-4852-a8c8-93774160324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall maximum observed score: 4\n",
      "Per‐biomarker maxima: [3 3 2 2 2 2 2 2 2 2 1 2 3 2 4 4 4 4 4 3 3 3 4 4 3 4 4 3 3 4 4 4 3 3 3 4 3\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall maximum observed score:\", data_mat.max())\n",
    "print(\"Per‐biomarker maxima:\", data_mat.max(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30806be-bf7d-4d39-9cb8-f52c1c5b1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_score_matrix(data_mat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_mat : np.ndarray  (shape = n_samples x n_biomarkers)\n",
    "        Raw dataset in which each column is a biomarker and each row is a sample.\n",
    "        Values are assumed to be non-negative integers (0 means “no score” or “missing”).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score_vals : np.ndarray  (shape = n_biomarkers x (max_score_overall+1))\n",
    "        Row i contains [0, 1, …, max_i] where max_i is the maximum value\n",
    "        seen in biomarker i.  Any cells beyond max_i are left as 0 padding.\n",
    "    \"\"\"\n",
    "    # number of biomarkers is the number of columns\n",
    "    n_biomarkers = data_mat.shape[1]\n",
    "\n",
    "    # overall width = global maximum + 1 (so the range 0..max fits)\n",
    "    max_score_overall = int(data_mat.max()) + 1\n",
    "\n",
    "    score_vals = np.zeros((n_biomarkers, max_score_overall), dtype=int)\n",
    "\n",
    "    for b in range(n_biomarkers):\n",
    "        max_b = int(data_mat[:, b].max())\n",
    "        # fill 0..max_b inclusive\n",
    "        score_vals[b, :max_b + 1] = np.arange(0, max_b + 1)\n",
    "\n",
    "    return score_vals\n",
    "Z_scores=build_score_matrix(data_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c828fa0-1117-4ef7-93ee-a90519fc7e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 0, 0],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 0],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_scores"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b72ba8a-4498-40ea-9dd7-967c9bd5a257",
   "metadata": {},
   "source": [
    "prob_nl.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627bc16-98fe-43d4-8a9f-2015d29aaf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a387ae0-68b6-474d-bf95-3f67e8b2a94b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy controls: 181 | PD/Prodromal: 1086\n",
      "Remaining biomarkers after filtering: 77\n",
      "NaNs in prob_nl: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prob_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 147\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# 14) Check for NaNs\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaNs in prob_nl:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39misnan(prob_nl)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaNs in prob_score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39misnan(\u001b[43mprob_score\u001b[49m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(prob_nl)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(prob_score)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are NaNs in the probability matrices. Please check data preprocessing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prob_score' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from pySuStaIn.OrdinalSustain import OrdinalSustain\n",
    "\n",
    "# 1) Load dataset\n",
    "df = pd.read_csv(\n",
    "    r'C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\result_4_long_format.csv',\n",
    "    sep=';',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# 2) Drop duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# 3) Split cohorts early\n",
    "df_healthy = df[(df[\"COHORT\"] == \"Healthy Control\") & (df[\"EVENT_ID\"] == \"V08\")].copy()\n",
    "df = df[df[\"EVENT_ID\"] == \"V08\"].copy()\n",
    "\n",
    "# 4) Define ordinal variables\n",
    "ordinal_vars = [\n",
    "    'COGCAT', 'COGDXCL', 'COGSTATE', 'FEATCOGFLC', 'FEATCRTSNS', 'FEATDCRARM',\n",
    "    'FEATDELHAL', 'FEATDEPRES', 'FEATDIMOLF', 'FEATDYSART', 'FEATDYSKIN',\n",
    "    'FEATDYSPHG', 'FEATDYSTNA', 'FEATMYCLNS', 'FEATNEURSS', 'FEATNOLEVO',\n",
    "    'FEATPOSHYP', 'FEATPST3YR', 'FEATPYRTCT', 'FEATSBDERM', 'FEATSEXDYS',\n",
    "    'FEATURNDYS', 'FEATWDGAIT', 'MCAABSTR', 'MCASER7', 'MCASNTNC', 'MRIRSLT',\n",
    "    'NP1ANXS', 'NP1APAT', 'NP1COG', 'NP1DPRS', 'NP1HALL', 'NP2DRES', 'NP2EAT',\n",
    "    'NP2FREZ', 'NP2HOBB', 'NP2HWRT', 'NP2HYGN', 'NP2RISE', 'NP2SALV',\n",
    "    'NP2SPCH', 'NP2SWAL', 'NP2TRMR', 'NP2TURN', 'NP2WALK', 'NP3PTRML',\n",
    "    'NP3RTALL', 'NP3RTARL', 'NP3SPCH', 'PTCGBOTH', 'STAIAD1', 'STAIAD10',\n",
    "    'STAIAD11', 'STAIAD12', 'STAIAD13', 'STAIAD14', 'STAIAD15', 'STAIAD16',\n",
    "    'STAIAD17', 'STAIAD18', 'STAIAD19', 'STAIAD2', 'STAIAD20', 'STAIAD21',\n",
    "    'STAIAD22', 'STAIAD23', 'STAIAD24', 'STAIAD25', 'STAIAD26', 'STAIAD27',\n",
    "    'STAIAD28', 'STAIAD29', 'STAIAD3', 'STAIAD30', 'STAIAD31', 'STAIAD32',\n",
    "    'STAIAD33', 'STAIAD34', 'STAIAD35', 'STAIAD36', 'STAIAD37', 'STAIAD38',\n",
    "    'STAIAD39', 'STAIAD4', 'STAIAD40', 'STAIAD5', 'STAIAD6', 'STAIAD7',\n",
    "    'STAIAD8', 'STAIAD9'\n",
    "]\n",
    "\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + ordinal_vars + [\"EVENT_ID\"]\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "# 5) Extract PD/Prodromal\n",
    "df_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])].copy()\n",
    "print(f\"Healthy controls: {df_healthy.shape[0]} | PD/Prodromal: {df_pd.shape[0]}\")\n",
    "\n",
    "# 6) Drop biomarkers with >20% missing\n",
    "null_fraction = df_pd[ordinal_vars].isna().mean()\n",
    "cols_to_drop = list(null_fraction[null_fraction > 0.20].index)\n",
    "ordinal_vars = [v for v in ordinal_vars if v not in cols_to_drop]\n",
    "df_pd.drop(columns=cols_to_drop, inplace=True)\n",
    "df_healthy.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 7) Drop biomarkers with only one unique value\n",
    "low_variance_vars = [v for v in ordinal_vars if df_pd[v].nunique() <= 1]\n",
    "if low_variance_vars:\n",
    "    print(f\"Dropping low-variance biomarkers: {low_variance_vars}\")\n",
    "    ordinal_vars = [v for v in ordinal_vars if v not in low_variance_vars]\n",
    "    df_pd.drop(columns=low_variance_vars, inplace=True)\n",
    "    df_healthy.drop(columns=low_variance_vars, inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"Remaining biomarkers after filtering: {len(ordinal_vars)}\")\n",
    "\n",
    "# 8) Drop rows with missing values\n",
    "df_pd.dropna(subset=ordinal_vars, inplace=True)\n",
    "df_healthy.dropna(subset=ordinal_vars, inplace=True)\n",
    "\n",
    "# 9) Create data matrices\n",
    "data_mat_healthy = df_healthy[ordinal_vars].astype(float).values\n",
    "data_mat_pd = df_pd[ordinal_vars].astype(float).values\n",
    "n_samples = data_mat_pd.shape[0]\n",
    "n_biomarkers = data_mat_pd.shape[1]\n",
    "\n",
    "# 10) Build score matrix\n",
    "def get_score_vals_padded(data_mat_healthy, data_mat_pd):\n",
    "    \"\"\"\n",
    "    Computes a padded matrix of score values for each biomarker.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_mat_healthy : np.ndarray\n",
    "        Matrix of shape (n_healthy_subjects, n_biomarkers).\n",
    "    \n",
    "    data_mat_pd : np.ndarray\n",
    "        Matrix of shape (n_pd_subjects, n_biomarkers).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    score_vals : np.ndarray\n",
    "        2D array of shape (n_biomarkers, max_num_scores), where each row contains\n",
    "        valid score values for that biomarker, padded with zeros if needed.\n",
    "    \"\"\"\n",
    "    # Combine the datasets\n",
    "    combined_data = np.vstack([data_mat_healthy, data_mat_pd])\n",
    "    n_biomarkers = combined_data.shape[1]\n",
    "\n",
    "    # Get maximum number of scores across all biomarkers\n",
    "    max_scores_per_biomarker = [int(combined_data[:, b].max()) + 1 for b in range(n_biomarkers)]\n",
    "    max_num_scores = max(max_scores_per_biomarker)\n",
    "\n",
    "    # Initialize score_vals matrix with zeros\n",
    "    score_vals = np.zeros((n_biomarkers, max_num_scores), dtype=int)\n",
    "\n",
    "    # Fill each row with valid scores\n",
    "    for b in range(n_biomarkers):\n",
    "        valid_scores = np.arange(0, max_scores_per_biomarker[b])\n",
    "        score_vals[b, :len(valid_scores)] = valid_scores\n",
    "\n",
    "    return score_vals\n",
    "score_vals = get_score_vals_padded(data_mat_healthy, data_mat_pd)\n",
    "# 11) Compute prob_nl\n",
    "prob_nl = np.zeros((n_samples, n_biomarkers))\n",
    "for j in range(n_biomarkers):\n",
    "    vals = data_mat_healthy[:, j]\n",
    "    mu, sigma = np.mean(vals), np.std(vals)\n",
    "    sigma = sigma if sigma > 0 else 0.1\n",
    "    prob_nl[:, j] = norm.pdf(data_mat_pd[:, j], loc=mu, scale=sigma)\n",
    "\n",
    "# 12) Compute score means and stds correctly\n",
    "unique_scores = sorted(set(np.unique(score_vals)))\n",
    "score_means = []\n",
    "score_stds = []\n",
    "for score in unique_scores:\n",
    "    means, stds = [], []\n",
    "    for biomarker in ordinal_vars:\n",
    "        vals = df_pd[biomarker]\n",
    "        subset = vals[vals == score]\n",
    "        if len(subset) >= 2:\n",
    "            m, s = subset.mean(), subset.std()\n",
    "        elif len(subset) == 1:\n",
    "            m = subset.iloc[0]\n",
    "            s = vals[vals != score].std()\n",
    "        else:\n",
    "            m, s = np.nan, np.nan\n",
    "        means.append(m)\n",
    "        stds.append(s)\n",
    "    score_means.append(np.array(means))\n",
    "    score_stds.append(np.array(stds))\n",
    "\n",
    "# 13) Build prob_score\n",
    "N_scores = len(score_means)\n",
    "\n",
    "# 14) Check for NaNs\n",
    "print(\"NaNs in prob_nl:\", np.isnan(prob_nl).sum())\n",
    "print(\"NaNs in prob_score:\", np.isnan(prob_score).sum())\n",
    "if np.isnan(prob_nl).any() or np.isnan(prob_score).any():\n",
    "    raise ValueError(\"There are NaNs in the probability matrices. Please check data preprocessing.\")\n",
    "\n",
    "# 15) Output directory\n",
    "output_folder = \"./ordinal_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 16) Run SuStaIn\n",
    "model = OrdinalSustain(\n",
    "    prob_nl=prob_nl,\n",
    "    prob_score=prob_score,\n",
    "    score_vals=score_vals,\n",
    "    biomarker_labels=ordinal_vars,\n",
    "    N_startpoints=25,\n",
    "    N_S_max=2,\n",
    "    N_iterations_MCMC=int(1e4),\n",
    "    output_folder=output_folder,\n",
    "    dataset_name=\"PD_ordinal_V08\",\n",
    "    use_parallel_startpoints=False,\n",
    "    seed=42\n",
    ")\n",
    "model.run_sustain_algorithm()\n",
    "\n",
    "# 17) Plot results\n",
    "figs, axs = model.plot_sustain_model(\n",
    "    samples_sequence=model.samples_sequence,\n",
    "    samples_f=model.samples_f,\n",
    "    n_samples=n_samples,\n",
    "    score_vals=score_vals,\n",
    "    biomarker_labels=ordinal_vars,\n",
    "    ml_f_EM=model.ml_f,\n",
    "    separate_subtypes=False\n",
    ")\n",
    "\n",
    "for i, fig in enumerate(figs):\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(output_folder, f\"sustain_plot_{i}.png\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081dc543-8d32-441a-9e76-92365cedc992",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mipdb\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipdb'"
     ]
    }
   ],
   "source": [
    "import time, ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf6bdcf-8c63-4857-bef7-83636e13663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516d9ca4-4a6a-4729-bcf0-935c3630e594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'which' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex‚cutable ou un fichier de commandes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ipdb\n",
      "Version: 0.13.13\n",
      "Summary: IPython-enabled pdb\n",
      "Home-page: https://github.com/gotcha/ipdb\n",
      "Author: Godefroid Chapelle\n",
      "Author-email: gotcha@bubblenet.be\n",
      "License: BSD\n",
      "Location: c:\\users\\nss_1\\anaconda3\\envs\\sustain_tutorial_env\\lib\\site-packages\n",
      "Requires: decorator, ipython, tomli\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!pip show ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a1fdd0-b5bf-4426-b5d6-7321ebee664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nss_1\\anaconda3\\envs\\sustain_tutorial_env\\python.exe\n",
      "C:\\Users\\nss_1\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "C:\\Users\\nss_1\\AppData\\Local\\Programs\\Python\\Python38-32\\python.exe\n",
      "C:\\Users\\nss_1\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n",
      "C:\\Users\\nss_1\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed20db0d-3011-4921-85f1-1bd7a7a02f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy controls: 181 | PD/Prodromal: 1086\n",
      "Remaining biomarkers after filtering: 77\n",
      "NaNs in prob_nl: 0\n",
      "NaNs in prob_score: 0\n",
      "Failed to find pickle file: ./ordinal_output\\pickle_files\\PD_ordinal_V08_subtype0.pickle. Running SuStaIn model for 0 subtype.\n",
      "Finding ML solution to 1 cluster problem\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 144\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# 16) Run SuStaIn\u001b[39;00m\n\u001b[0;32m    131\u001b[0m model \u001b[38;5;241m=\u001b[39m OrdinalSustain(\n\u001b[0;32m    132\u001b[0m     prob_nl\u001b[38;5;241m=\u001b[39mprob_nl,\n\u001b[0;32m    133\u001b[0m     prob_score\u001b[38;5;241m=\u001b[39mprob_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    143\u001b[0m )\n\u001b[1;32m--> 144\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_sustain_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# 17) Plot results\u001b[39;00m\n\u001b[0;32m    147\u001b[0m figs, axs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mplot_sustain_model(\n\u001b[0;32m    148\u001b[0m     samples_sequence\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39msamples_sequence,\n\u001b[0;32m    149\u001b[0m     samples_f\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39msamples_f,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     separate_subtypes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    155\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pySuStaIn\\AbstractSustain.py:164\u001b[0m, in \u001b[0;36mAbstractSustain.run_sustain_algorithm\u001b[1;34m(self, plot, plot_format, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find pickle file: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m pickle_filename_s \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Running SuStaIn model for \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m subtype.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    159\u001b[0m     ml_sequence_EM,     \\\n\u001b[0;32m    160\u001b[0m     ml_f_EM,            \\\n\u001b[0;32m    161\u001b[0m     ml_likelihood_EM,   \\\n\u001b[0;32m    162\u001b[0m     ml_sequence_mat_EM, \\\n\u001b[0;32m    163\u001b[0m     ml_f_mat_EM,        \\\n\u001b[1;32m--> 164\u001b[0m     ml_likelihood_mat_EM        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_ml_sustain_model_nplus1_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sustainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_sequence_prev_EM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_f_prev_EM\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#self.__estimate_ml_sustain_model_nplus1_clusters(self.__data, ml_sequence_prev_EM, ml_f_prev_EM)\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     seq_init                    \u001b[38;5;241m=\u001b[39m ml_sequence_EM\n\u001b[0;32m    167\u001b[0m     f_init                      \u001b[38;5;241m=\u001b[39m ml_f_EM\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pySuStaIn\\AbstractSustain.py:623\u001b[0m, in \u001b[0;36mAbstractSustain._estimate_ml_sustain_model_nplus1_clusters\u001b[1;34m(self, sustainData, ml_sequence_prev, ml_f_prev)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m N_S \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;66;03m# If the number of subtypes is 1, fit a single linear z-score model\u001b[39;00m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinding ML solution to 1 cluster problem\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    618\u001b[0m     ml_sequence,        \\\n\u001b[0;32m    619\u001b[0m     ml_f,               \\\n\u001b[0;32m    620\u001b[0m     ml_likelihood,      \\\n\u001b[0;32m    621\u001b[0m     ml_sequence_mat,    \\\n\u001b[0;32m    622\u001b[0m     ml_f_mat,           \\\n\u001b[1;32m--> 623\u001b[0m     ml_likelihood_mat               \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_ml\u001b[49m\u001b[43m(\u001b[49m\u001b[43msustainData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverall ML likelihood is\u001b[39m\u001b[38;5;124m'\u001b[39m, ml_likelihood)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;66;03m# If the number of subtypes is greater than 1, go through each subtype\u001b[39;00m\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# in turn and try splitting into two subtypes\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pySuStaIn\\AbstractSustain.py:715\u001b[0m, in \u001b[0;36mAbstractSustain._find_ml\u001b[1;34m(self, sustainData)\u001b[0m\n\u001b[0;32m    712\u001b[0m pool_output_list                    \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mmap(partial_iter, seed_sequences\u001b[38;5;241m.\u001b[39mspawn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_startpoints))\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m~\u001b[39m\u001b[38;5;28misinstance\u001b[39m(pool_output_list, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 715\u001b[0m     pool_output_list                \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpool_output_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m ml_sequence_mat                     \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, sustainData\u001b[38;5;241m.\u001b[39mgetNumStages(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_startpoints)) \u001b[38;5;66;03m#np.zeros((1, self.stage_zscore.shape[1], self.N_startpoints))\u001b[39;00m\n\u001b[0;32m    718\u001b[0m ml_f_mat                            \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_startpoints))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pySuStaIn\\AbstractSustain.py:748\u001b[0m, in \u001b[0;36mAbstractSustain._find_ml_iteration\u001b[1;34m(self, sustainData, seed_seq)\u001b[0m\n\u001b[0;32m    740\u001b[0m seq_init                        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialise_sequence(sustainData, rng)\n\u001b[0;32m    741\u001b[0m f_init                          \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    743\u001b[0m this_ml_sequence,   \\\n\u001b[0;32m    744\u001b[0m this_ml_f,          \\\n\u001b[0;32m    745\u001b[0m this_ml_likelihood, \\\n\u001b[0;32m    746\u001b[0m _,                  \\\n\u001b[0;32m    747\u001b[0m _,                  \\\n\u001b[1;32m--> 748\u001b[0m _                               \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_em\u001b[49m\u001b[43m(\u001b[49m\u001b[43msustainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m this_ml_sequence, this_ml_f, this_ml_likelihood\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pySuStaIn\\AbstractSustain.py:903\u001b[0m, in \u001b[0;36mAbstractSustain._perform_em\u001b[1;34m(self, sustainData, current_sequence, current_f, rng)\u001b[0m\n\u001b[0;32m    898\u001b[0m samples_likelihood[\u001b[38;5;241m0\u001b[39m]               \u001b[38;5;241m=\u001b[39m current_likelihood\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m terminate \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    901\u001b[0m     candidate_sequence,     \\\n\u001b[0;32m    902\u001b[0m     candidate_f,            \\\n\u001b[1;32m--> 903\u001b[0m     candidate_likelihood            \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimise_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43msustainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m     HAS_converged                   \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfabs((candidate_likelihood \u001b[38;5;241m-\u001b[39m current_likelihood) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(candidate_likelihood, current_likelihood)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m HAS_converged:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m#print('EM converged in', iteration + 1, 'iterations')\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pySuStaIn\\OrdinalSustain.py:276\u001b[0m, in \u001b[0;36mOrdinalSustain._optimise_parameters\u001b[1;34m(self, sustainData, S_init, f_init, rng)\u001b[0m\n\u001b[0;32m    273\u001b[0m new_sequence            \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([current_sequence[np\u001b[38;5;241m.\u001b[39marange(move_event_to)], [selected_event], current_sequence[np\u001b[38;5;241m.\u001b[39marange(move_event_to, N \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)]])\n\u001b[0;32m    274\u001b[0m possible_sequences[index, :] \u001b[38;5;241m=\u001b[39m new_sequence\n\u001b[1;32m--> 276\u001b[0m possible_p_perm_k[:, :, index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_likelihood_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43msustainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m p_perm_k[:, :, s]       \u001b[38;5;241m=\u001b[39m possible_p_perm_k[:, :, index]\n\u001b[0;32m    279\u001b[0m total_prob_stage        \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(p_perm_k \u001b[38;5;241m*\u001b[39m f_val_mat, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pySuStaIn\\OrdinalSustain.py:196\u001b[0m, in \u001b[0;36mOrdinalSustain._calculate_likelihood_stage\u001b[1;34m(self, sustainData, S)\u001b[0m\n\u001b[0;32m    194\u001b[0m     bool_IS_normal \u001b[38;5;241m=\u001b[39m IS_normal\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    195\u001b[0m     bool_IS_abnormal \u001b[38;5;241m=\u001b[39m IS_abnormal\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m     p_perm_k[:,j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(N\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mmultiply(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43msustainData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprob_score\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_reached\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbool_IS_abnormal\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,np\u001b[38;5;241m.\u001b[39mprod(sustainData\u001b[38;5;241m.\u001b[39mprob_nl[:,bool_IS_normal],\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p_perm_k\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3100\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2979\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[0;32m   2980\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2981\u001b[0m          initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2982\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2983\u001b[0m \u001b[38;5;124;03m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[0;32m   2984\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3098\u001b[0m \u001b[38;5;124;03m    10\u001b[39;00m\n\u001b[0;32m   3099\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3101\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from pySuStaIn.OrdinalSustain import OrdinalSustain\n",
    "\n",
    "# 1) Load dataset\n",
    "df = pd.read_csv(\n",
    "    r'C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\result_4_long_format.csv',\n",
    "    sep=';',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# 2) Drop duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# 3) Split cohorts early\n",
    "df_healthy = df[(df[\"COHORT\"] == \"Healthy Control\") & (df[\"EVENT_ID\"] == \"V08\")].copy()\n",
    "df = df[df[\"EVENT_ID\"] == \"V08\"].copy()\n",
    "\n",
    "# 4) Define ordinal variables\n",
    "ordinal_vars = [\n",
    "    'COGCAT', 'COGDXCL', 'COGSTATE', 'FEATCOGFLC', 'FEATCRTSNS', 'FEATDCRARM',\n",
    "    'FEATDELHAL', 'FEATDEPRES', 'FEATDIMOLF', 'FEATDYSART', 'FEATDYSKIN',\n",
    "    'FEATDYSPHG', 'FEATDYSTNA', 'FEATMYCLNS', 'FEATNEURSS', 'FEATNOLEVO',\n",
    "    'FEATPOSHYP', 'FEATPST3YR', 'FEATPYRTCT', 'FEATSBDERM', 'FEATSEXDYS',\n",
    "    'FEATURNDYS', 'FEATWDGAIT', 'MCAABSTR', 'MCASER7', 'MCASNTNC', 'MRIRSLT',\n",
    "    'NP1ANXS', 'NP1APAT', 'NP1COG', 'NP1DPRS', 'NP1HALL', 'NP2DRES', 'NP2EAT',\n",
    "    'NP2FREZ', 'NP2HOBB', 'NP2HWRT', 'NP2HYGN', 'NP2RISE', 'NP2SALV',\n",
    "    'NP2SPCH', 'NP2SWAL', 'NP2TRMR', 'NP2TURN', 'NP2WALK', 'NP3PTRML',\n",
    "    'NP3RTALL', 'NP3RTARL', 'NP3SPCH', 'PTCGBOTH', 'STAIAD1', 'STAIAD10',\n",
    "    'STAIAD11', 'STAIAD12', 'STAIAD13', 'STAIAD14', 'STAIAD15', 'STAIAD16',\n",
    "    'STAIAD17', 'STAIAD18', 'STAIAD19', 'STAIAD2', 'STAIAD20', 'STAIAD21',\n",
    "    'STAIAD22', 'STAIAD23', 'STAIAD24', 'STAIAD25', 'STAIAD26', 'STAIAD27',\n",
    "    'STAIAD28', 'STAIAD29', 'STAIAD3', 'STAIAD30', 'STAIAD31', 'STAIAD32',\n",
    "    'STAIAD33', 'STAIAD34', 'STAIAD35', 'STAIAD36', 'STAIAD37', 'STAIAD38',\n",
    "    'STAIAD39', 'STAIAD4', 'STAIAD40', 'STAIAD5', 'STAIAD6', 'STAIAD7',\n",
    "    'STAIAD8', 'STAIAD9'\n",
    "]\n",
    "\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + ordinal_vars + [\"EVENT_ID\"]\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "# 5) Extract PD/Prodromal\n",
    "df_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])].copy()\n",
    "print(f\"Healthy controls: {df_healthy.shape[0]} | PD/Prodromal: {df_pd.shape[0]}\")\n",
    "\n",
    "# 6) Drop biomarkers with >20% missing\n",
    "null_fraction = df_pd[ordinal_vars].isna().mean()\n",
    "cols_to_drop = list(null_fraction[null_fraction > 0.20].index)\n",
    "ordinal_vars = [v for v in ordinal_vars if v not in cols_to_drop]\n",
    "df_pd.drop(columns=cols_to_drop, inplace=True)\n",
    "df_healthy.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 7) Drop biomarkers with only one unique value\n",
    "low_variance_vars = [v for v in ordinal_vars if df_pd[v].nunique() <= 1]\n",
    "if low_variance_vars:\n",
    "    print(f\"Dropping low-variance biomarkers: {low_variance_vars}\")\n",
    "    ordinal_vars = [v for v in ordinal_vars if v not in low_variance_vars]\n",
    "    df_pd.drop(columns=low_variance_vars, inplace=True)\n",
    "    df_healthy.drop(columns=low_variance_vars, inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"Remaining biomarkers after filtering: {len(ordinal_vars)}\")\n",
    "\n",
    "# 8) Drop rows with missing values\n",
    "df_pd.dropna(subset=ordinal_vars, inplace=True)\n",
    "df_healthy.dropna(subset=ordinal_vars, inplace=True)\n",
    "\n",
    "# 9) Create data matrices\n",
    "data_mat_healthy = df_healthy[ordinal_vars].astype(float).values\n",
    "data_mat_pd = df_pd[ordinal_vars].astype(float).values\n",
    "n_samples = data_mat_pd.shape[0]\n",
    "n_biomarkers = data_mat_pd.shape[1]\n",
    "\n",
    "# 10) Build score matrix\n",
    "def get_score_vals_padded(data_mat_healthy, data_mat_pd):\n",
    "    combined_data = np.vstack([data_mat_healthy, data_mat_pd])\n",
    "    n_biomarkers = combined_data.shape[1]\n",
    "    max_scores_per_biomarker = [int(combined_data[:, b].max()) + 1 for b in range(n_biomarkers)]\n",
    "    max_num_scores = max(max_scores_per_biomarker)\n",
    "    score_vals = np.zeros((n_biomarkers, max_num_scores), dtype=int)\n",
    "    for b in range(n_biomarkers):\n",
    "        valid_scores = np.arange(0, max_scores_per_biomarker[b])\n",
    "        score_vals[b, :len(valid_scores)] = valid_scores\n",
    "    return score_vals\n",
    "\n",
    "score_vals = get_score_vals_padded(data_mat_healthy, data_mat_pd)\n",
    "\n",
    "# 11) Compute prob_nl\n",
    "prob_nl = np.zeros((n_samples, n_biomarkers))\n",
    "for j in range(n_biomarkers):\n",
    "    vals = data_mat_healthy[:, j]\n",
    "    mu, sigma = np.mean(vals), np.std(vals)\n",
    "    sigma = sigma if sigma > 0 else 0.1\n",
    "    prob_nl[:, j] = norm.pdf(data_mat_pd[:, j], loc=mu, scale=sigma)\n",
    "\n",
    "# 12) Build p_score_dist matrix\n",
    "score_vals_flat = sorted(set(np.unique(score_vals)))\n",
    "N_scores = len(score_vals_flat)\n",
    "p_score_dist = np.zeros((N_scores, N_scores + 1))  # rows = true scores (1 to N), cols = observed (0 to N)\n",
    "for z in range(1, N_scores + 1):  # true score from 1 to N_scores\n",
    "    for s in range(N_scores + 1):  # observed score from 0 to N_scores\n",
    "        p_score_dist[z - 1, s] = norm.pdf(s, loc=z, scale=1.0)\n",
    "    p_score_dist[z - 1] /= np.sum(p_score_dist[z - 1])  # normalize\n",
    "\n",
    "# 13) Compute prob_score\n",
    "def compute_prob_score(data_mat_pd, p_score_dist):\n",
    "    n_samples, n_biomarkers = data_mat_pd.shape\n",
    "    N_scores = p_score_dist.shape[0]\n",
    "    prob_score = np.zeros((n_samples, n_biomarkers, N_scores))\n",
    "    for z in range(N_scores):\n",
    "        for s in range(N_scores + 1):\n",
    "            match_indices = (data_mat_pd == s)\n",
    "            prob_score[match_indices, z] = p_score_dist[z, s]\n",
    "    return prob_score\n",
    "\n",
    "prob_score = compute_prob_score(data_mat_pd, p_score_dist)\n",
    "\n",
    "# 14) Check for NaNs\n",
    "print(\"NaNs in prob_nl:\", np.isnan(prob_nl).sum())\n",
    "print(\"NaNs in prob_score:\", np.isnan(prob_score).sum())\n",
    "if np.isnan(prob_nl).any() or np.isnan(prob_score).any():\n",
    "    raise ValueError(\"There are NaNs in the probability matrices. Please check data preprocessing.\")\n",
    "\n",
    "# 15) Output directory\n",
    "output_folder = \"./ordinal_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 16) Run SuStaIn\n",
    "model = OrdinalSustain(\n",
    "    prob_nl=prob_nl,\n",
    "    prob_score=prob_score,\n",
    "    score_vals=score_vals,\n",
    "    biomarker_labels=ordinal_vars,\n",
    "    N_startpoints=25,\n",
    "    N_S_max=2,\n",
    "    N_iterations_MCMC=int(1e4),\n",
    "    output_folder=output_folder,\n",
    "    dataset_name=\"PD_ordinal_V08\",\n",
    "    use_parallel_startpoints=False,\n",
    "    seed=42\n",
    ")\n",
    "model.run_sustain_algorithm()\n",
    "\n",
    "# 17) Plot results\n",
    "figs, axs = model.plot_sustain_model(\n",
    "    samples_sequence=model.samples_sequence,\n",
    "    samples_f=model.samples_f,\n",
    "    n_samples=n_samples,\n",
    "    score_vals=score_vals,\n",
    "    biomarker_labels=ordinal_vars,\n",
    "    ml_f_EM=model.ml_f,\n",
    "    separate_subtypes=False\n",
    ")\n",
    "\n",
    "for i, fig in enumerate(figs):\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(output_folder, f\"sustain_plot_{i}.png\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a3a3a-6a30-48e6-a752-57866f5a0d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy controls = 181 | PD/Prodromal = 1086\n",
      "Final ordinal variables: ['MCATOT', 'NP1RTOT', 'NP2PTOT', 'NP3TOT', 'AGE_AT_VISIT', 'GDS_Total_Score', 'MSEADLG']\n",
      "\n",
      "Data validation:\n",
      "Number of samples: 930\n",
      "Number of biomarkers: 7\n",
      "Max score across biomarkers: 101\n",
      "prob_nl shape: (930, 7)\n",
      "prob_score shape: (930, 7, 101)\n",
      "score_vals shape: (7, 101)\n",
      "Failed to find pickle file: ./ordinal_output_newvars\\pickle_files\\PD_ordinal_V08_newvars_subtype0.pickle. Running SuStaIn model for 0 subtype.\n",
      "Finding ML solution to 1 cluster problem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from pySuStaIn.OrdinalSustain import OrdinalSustain\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 1. Load dataset\n",
    "csv_path = Path(r\"C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\result_4_long_format.csv\")\n",
    "df = pd.read_csv(csv_path, sep=\";\", low_memory=False)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 2. Compute STAI and GDS scores\n",
    "state_items = [f\"STAIDAD{i}\" for i in range(1, 21)]\n",
    "trait_items = [f\"STAIDAD{i}\" for i in range(21, 41)]\n",
    "reverse_stai = {\n",
    "    \"STAIDAD1\", \"STAIDAD2\", \"STAIDAD5\", \"STAIDAD8\", \"STAIDAD10\", \"STAIDAD11\",\n",
    "    \"STAIDAD15\", \"STAIDAD16\", \"STAIDAD19\", \"STAIDAD20\", \"STAIDAD21\", \"STAIDAD23\",\n",
    "    \"STAIDAD26\", \"STAIDAD27\", \"STAIDAD30\", \"STAIDAD33\", \"STAIDAD34\", \"STAIDAD36\",\n",
    "    \"STAIDAD39\", \"STAIDAD40\"\n",
    "}\n",
    "\n",
    "# Only reverse score items that exist in the dataframe\n",
    "available_items = set(df.columns) & reverse_stai\n",
    "for col in available_items:\n",
    "    df[col] = 5 - df[col]\n",
    "\n",
    "# Calculate scores only for items that exist\n",
    "existing_state_items = [item for item in state_items if item in df.columns]\n",
    "existing_trait_items = [item for item in trait_items if item in df.columns]\n",
    "\n",
    "if existing_state_items:\n",
    "    df[\"STAI_State_Anxiety\"] = df[existing_state_items].sum(axis=1)\n",
    "if existing_trait_items:\n",
    "    df[\"STAI_Trait_Anxiety\"] = df[existing_trait_items].sum(axis=1)\n",
    "\n",
    "gds_items = [\n",
    "    \"GDSAFRAD\", \"GDSALIVE\", \"GDSBETER\", \"GDSBORED\", \"GDSDROPD\", \"GDSEMPTY\",\n",
    "    \"GDSENRGY\", \"GDSGSPIR\", \"GDSHAPPY\", \"GDSHLPLS\", \"GDSHOME\", \"GDSHOPLS\",\n",
    "    \"GDSMEMRY\", \"GDSSATIS\", \"GDSWRTLS\"\n",
    "]\n",
    "gds_reverse = {\"GDSAFRAD\", \"GDSHAPPY\", \"GDSSATIS\"}\n",
    "\n",
    "# Only reverse score items that exist in the dataframe\n",
    "available_gds_items = set(df.columns) & gds_reverse\n",
    "for col in available_gds_items:\n",
    "    df[col] = 1 - df[col]\n",
    "\n",
    "existing_gds_items = [item for item in gds_items if item in df.columns]\n",
    "if existing_gds_items:\n",
    "    df[\"GDS_Total_Score\"] = df[existing_gds_items].sum(axis=1)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 3. Keep only visit V08 and essential columns\n",
    "initial_ordinal = [\n",
    "    \"MCATOT\", \"NP1RTOT\", \"NP2PTOT\", \"NP3TOT\",\n",
    "    \"AGE_AT_VISIT\",\n",
    "    \"STAI_State_Anxiety\", \"STAI_Trait_Anxiety\",\n",
    "    \"GDS_Total_Score\", \"MSEADLG\"\n",
    "]\n",
    "meta_cols = [\"PATNO\", \"FINAL_SEX_ENCODED\", \"COHORT\", \"EVENT_ID\"]\n",
    "\n",
    "# Only keep columns that exist in the dataframe\n",
    "existing_ordinal = [col for col in initial_ordinal if col in df.columns]\n",
    "df = df[df[\"EVENT_ID\"] == \"V08\"].loc[:, meta_cols + existing_ordinal]\n",
    "\n",
    "# Optional: treat age as ordinal (nearest year)\n",
    "if \"AGE_AT_VISIT\" in df.columns:\n",
    "    df[\"AGE_AT_VISIT\"] = df[\"AGE_AT_VISIT\"].round().astype(int)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 4. Split cohorts\n",
    "df_healthy = df[df[\"COHORT\"] == \"Healthy Control\"].copy()\n",
    "df_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])].copy()\n",
    "print(f\"Healthy controls = {df_healthy.shape[0]} | PD/Prodromal = {df_pd.shape[0]}\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 5. Drop high-missing columns (≥20 %)\n",
    "null_fraction = df_pd[existing_ordinal].isna().mean()\n",
    "drop_cols = null_fraction[null_fraction > 0.20].index.tolist()\n",
    "df_pd.drop(columns=drop_cols, inplace=True)\n",
    "df_healthy.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 6. Drop zero/near-zero-variance biomarkers\n",
    "remaining_cols = [col for col in existing_ordinal if col not in drop_cols]\n",
    "low_var = [v for v in remaining_cols if df_pd[v].nunique(dropna=True) <= 1]\n",
    "df_pd.drop(columns=low_var, inplace=True)\n",
    "df_healthy.drop(columns=low_var, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 7. Final list of ordinal biomarkers (after all cleaning)\n",
    "ordinal_vars = [\n",
    "    c for c in df_pd.columns\n",
    "    if c not in meta_cols            # remove meta\n",
    "    and c not in drop_cols\n",
    "    and c not in low_var\n",
    "]\n",
    "print(\"Final ordinal variables:\", ordinal_vars)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 8. Drop rows with missing values in remaining biomarkers\n",
    "df_pd.dropna(subset=ordinal_vars, inplace=True)\n",
    "df_healthy.dropna(subset=ordinal_vars, inplace=True)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 9. Build data matrices\n",
    "data_mat_healthy = df_healthy[ordinal_vars].astype(float).values\n",
    "data_mat_pd = df_pd[ordinal_vars].astype(float).values\n",
    "\n",
    "n_samples, n_biomarkers = data_mat_pd.shape\n",
    "assert len(ordinal_vars) == n_biomarkers, \"Column mismatch after cleaning\"\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 10. Create score_vals (padded)\n",
    "def get_score_vals_padded(mat_h, mat_pd):\n",
    "    combined = np.vstack([mat_h, mat_pd])\n",
    "    max_scores = (combined.max(axis=0) + 1).astype(int)\n",
    "    max_len = max(max_scores)\n",
    "    score_vals = np.zeros((combined.shape[1], max_len), dtype=int)\n",
    "    for i, m in enumerate(max_scores):\n",
    "        score_vals[i, :m] = np.arange(m)\n",
    "    return score_vals\n",
    "\n",
    "score_vals = get_score_vals_padded(data_mat_healthy, data_mat_pd)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 11. prob_nl (P(normal | value))\n",
    "prob_nl = np.zeros((n_samples, n_biomarkers))\n",
    "for j in range(n_biomarkers):\n",
    "    mu, sigma = data_mat_healthy[:, j].mean(), data_mat_healthy[:, j].std()\n",
    "    # Add small epsilon to prevent divide-by-zero\n",
    "    prob_nl[:, j] = norm.pdf(data_mat_pd[:, j], loc=mu, scale=max(sigma, 0.1)) + 1e-10\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 12. prob_score (P(score | latent-z)) - Corrected implementation\n",
    "# Get the maximum score for each biomarker\n",
    "max_scores_per_biomarker = [int(np.max(data_mat_pd[:, i])) + 1 for i in range(n_biomarkers)]\n",
    "max_score = max(max_scores_per_biomarker)\n",
    "\n",
    "# Initialize prob_score with correct dimensions (n_samples × n_biomarkers × max_score)\n",
    "prob_score = np.zeros((n_samples, n_biomarkers, max_score))\n",
    "\n",
    "for j in range(n_biomarkers):\n",
    "    # Get healthy control statistics for this biomarker\n",
    "    mu, sigma = data_mat_healthy[:, j].mean(), data_mat_healthy[:, j].std()\n",
    "    sigma = max(sigma, 0.1)  # Prevent division by zero\n",
    "    \n",
    "    # Create probability distribution for each possible score\n",
    "    for s in range(max_score):\n",
    "        # Probability of score s given normal distribution\n",
    "        prob_score[:, j, s] = norm.pdf(s, loc=mu, scale=sigma)\n",
    "    \n",
    "    # Normalize so probabilities sum to 1 for each sample\n",
    "    prob_score[:, j, :] = prob_score[:, j, :] / (prob_score[:, j, :].sum(axis=1, keepdims=True) + 1e-10)\n",
    "\n",
    "# Data validation checks\n",
    "print(\"\\nData validation:\")\n",
    "print(f\"Number of samples: {n_samples}\")\n",
    "print(f\"Number of biomarkers: {n_biomarkers}\")\n",
    "print(f\"Max score across biomarkers: {max_score}\")\n",
    "print(f\"prob_nl shape: {prob_nl.shape}\")\n",
    "print(f\"prob_score shape: {prob_score.shape}\")\n",
    "print(f\"score_vals shape: {score_vals.shape}\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 13. Run Ordinal SuStaIn\n",
    "output_folder = \"./ordinal_output_newvars\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    model = OrdinalSustain(\n",
    "        prob_nl=prob_nl,\n",
    "        prob_score=prob_score,\n",
    "        score_vals=score_vals,\n",
    "        biomarker_labels=ordinal_vars,\n",
    "        N_startpoints=25,\n",
    "        N_S_max=2,\n",
    "        N_iterations_MCMC=10_000,\n",
    "        output_folder=output_folder,\n",
    "        dataset_name=\"PD_ordinal_V08_newvars\",\n",
    "        use_parallel_startpoints=False,\n",
    "        seed=42,\n",
    "    )\n",
    "    model.run_sustain_algorithm()\n",
    "except Exception as e:\n",
    "    print(f\"Error running SuStaIn: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 14. Plot & save\n",
    "try:\n",
    "    figs, _ = model.plot_sustain_model(\n",
    "        samples_sequence=model.samples_sequence,\n",
    "        samples_f=model.samples_f,\n",
    "        n_samples=n_samples,\n",
    "        score_vals=score_vals,\n",
    "        biomarker_labels=ordinal_vars,\n",
    "        ml_f_EM=model.ml_f,\n",
    "        separate_subtypes=False,\n",
    "    )\n",
    "\n",
    "    for i, fig in enumerate(figs):\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(output_folder, f\"sustain_plot_{i}.png\"))\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting results: {str(e)}\")\n",
    "\n",
    "# Optional: Plot biomarker distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(3, n_biomarkers)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.hist(data_mat_pd[:, i], bins=20, alpha=0.5, label='PD')\n",
    "    plt.hist(data_mat_healthy[:, i], bins=20, alpha=0.5, label='Healthy')\n",
    "    plt.title(ordinal_vars[i])\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ebea306-51bc-44b0-9c1e-5a2ea585645b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_nl shape : (930, 10)\n",
      "prob_score   : (930, 10, 101)\n",
      "#labels      : 9\n"
     ]
    }
   ],
   "source": [
    "print(\"prob_nl shape :\", prob_nl.shape)        # should be (n_subjects, n_biomarkers)\n",
    "print(\"prob_score   :\", prob_score.shape)      # should be (n_subjects, n_biomarkers, N_scores)\n",
    "print(\"#labels      :\", len(ordinal_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22cbde6e-98f6-421e-baf1-9f0ddebb221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ordinal_vars: ['MCATOT', 'NP1RTOT', 'NP2PTOT', 'NP3TOT', 'AGE_AT_VISIT', 'STAI_State_Anxiety', 'STAI_Trait_Anxiety', 'GDS_Total_Score', 'MSEADLG']\n",
      "data_mat_pd shape: (930, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final ordinal_vars:\", ordinal_vars)\n",
    "print(\"data_mat_pd shape:\", data_mat_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97ca1eb6-105e-49b7-ac8b-ed909c60e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected ordinal_vars: ['AGE_AT_VISIT', 'MCATOT', 'NP1RTOT', 'NP2PTOT', 'NP3TOT', 'AGE_AT_VISIT', 'STAI_State_Anxiety', 'STAI_Trait_Anxiety', 'GDS_Total_Score', 'MSEADLG']\n"
     ]
    }
   ],
   "source": [
    "# Remove any non-ordinal fields\n",
    "non_ordinal = [\"PATNO\", \"FINAL_SEX_ENCODED\", \"COHORT\", \"EVENT_ID\"]\n",
    "ordinal_vars = [col for col in df_pd.columns if col not in non_ordinal]\n",
    "print(\"Corrected ordinal_vars:\", ordinal_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0fe7b89-e9eb-4cf6-9ea3-9a615e66452b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG PROBABILITY VALUES ---\n",
      "Sample prob_nl values:\n",
      "prob_nl[0,0] = 1.1532e-03\n",
      "prob_nl[0,1] = 3.1411e+00\n",
      "prob_nl[0,2] = 7.6946e-22\n",
      "prob_nl[1,0] = 1.1532e-03\n",
      "prob_nl[1,1] = 3.1411e+00\n",
      "prob_nl[1,2] = 3.9894e+00\n",
      "prob_nl[2,0] = 1.1532e-03\n",
      "prob_nl[2,1] = 3.1411e+00\n",
      "prob_nl[2,2] = 3.9894e+00\n",
      "\n",
      "Sample prob_score values (first 3 score levels):\n",
      "prob_score[0,0,0:3] = ['2.5702e-01', '4.0083e-01', '2.4311e-01']\n",
      "prob_score[0,1,0:3] = ['4.2376e-01', '2.4311e-01', '5.4246e-02']\n",
      "prob_score[0,2,0:3] = ['4.2376e-01', '2.4311e-01', '5.4246e-02']\n",
      "prob_score[1,0,0:3] = ['2.5702e-01', '4.0083e-01', '2.4311e-01']\n",
      "prob_score[1,1,0:3] = ['4.2376e-01', '2.4311e-01', '5.4246e-02']\n",
      "prob_score[1,2,0:3] = ['2.5702e-01', '5.4246e-02', '4.4528e-03']\n",
      "prob_score[2,0,0:3] = ['2.5702e-01', '4.0083e-01', '2.4311e-01']\n",
      "prob_score[2,1,0:3] = ['4.2376e-01', '2.4311e-01', '5.4246e-02']\n",
      "prob_score[2,2,0:3] = ['2.5702e-01', '5.4246e-02', '4.4528e-03']\n",
      "\n",
      "Total zero values in prob_nl: 1\n",
      "Total zero values in prob_score: 0\n"
     ]
    }
   ],
   "source": [
    "# === DEBUG PRINT BLOCK ===\n",
    "print(\"\\n--- DEBUG PROBABILITY VALUES ---\")\n",
    "\n",
    "# Print sample values of prob_nl\n",
    "print(\"Sample prob_nl values:\")\n",
    "for i in range(3):  # first 3 subjects\n",
    "    for j in range(3):  # first 3 biomarkers\n",
    "        print(f\"prob_nl[{i},{j}] = {prob_nl[i, j]:.4e}\")\n",
    "\n",
    "# Print sample values of prob_score\n",
    "print(\"\\nSample prob_score values (first 3 score levels):\")\n",
    "for i in range(3):  # first 3 subjects\n",
    "    for j in range(3):  # first 3 biomarkers\n",
    "        values = [f\"{prob_score[i, j, s]:.4e}\" for s in range(min(3, prob_score.shape[2]))]\n",
    "        print(f\"prob_score[{i},{j},0:{len(values)}] = {values}\")\n",
    "\n",
    "# Count total zeros in prob_nl and prob_score\n",
    "print(f\"\\nTotal zero values in prob_nl: {(prob_nl == 0).sum()}\")\n",
    "print(f\"Total zero values in prob_score: {(prob_score == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24233f8-dc4c-4280-bd9e-2a76921424bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy controls: 181 | PD/Prodromal: 1086\n",
      "Remaining biomarkers after filtering: 77\n",
      "NaNs in prob_nl: 0\n",
      "NaNs in prob_score: 0\n",
      "Failed to find pickle file: ./ordinal_output\\pickle_files\\PD_ordinal_V08_subtype0.pickle. Running SuStaIn model for 0 subtype.\n",
      "Finding ML solution to 1 cluster problem\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from pySuStaIn.OrdinalSustain import OrdinalSustain\n",
    "\n",
    "# 1) Load dataset\n",
    "df = pd.read_csv(\n",
    "    r'C:\\Users\\nss_1\\Desktop\\SustalIn\\pySuStaIn\\notebooks\\result_4_long_format.csv',\n",
    "    sep=';',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# 2) Drop duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# 3) Split cohorts early\n",
    "df_healthy = df[(df[\"COHORT\"] == \"Healthy Control\") & (df[\"EVENT_ID\"] == \"V08\")].copy()\n",
    "df = df[df[\"EVENT_ID\"] == \"V08\"].copy()\n",
    "\n",
    "# 4) Define ordinal variables\n",
    "ordinal_vars = [\n",
    "    'COGCAT', 'COGDXCL', 'COGSTATE', 'FEATCOGFLC', 'FEATCRTSNS', 'FEATDCRARM',\n",
    "    'FEATDELHAL', 'FEATDEPRES', 'FEATDIMOLF', 'FEATDYSART', 'FEATDYSKIN',\n",
    "    'FEATDYSPHG', 'FEATDYSTNA', 'FEATMYCLNS', 'FEATNEURSS', 'FEATNOLEVO',\n",
    "    'FEATPOSHYP', 'FEATPST3YR', 'FEATPYRTCT', 'FEATSBDERM', 'FEATSEXDYS',\n",
    "    'FEATURNDYS', 'FEATWDGAIT', 'MCAABSTR', 'MCASER7', 'MCASNTNC', 'MRIRSLT',\n",
    "    'NP1ANXS', 'NP1APAT', 'NP1COG', 'NP1DPRS', 'NP1HALL', 'NP2DRES', 'NP2EAT',\n",
    "    'NP2FREZ', 'NP2HOBB', 'NP2HWRT', 'NP2HYGN', 'NP2RISE', 'NP2SALV',\n",
    "    'NP2SPCH', 'NP2SWAL', 'NP2TRMR', 'NP2TURN', 'NP2WALK', 'NP3PTRML',\n",
    "    'NP3RTALL', 'NP3RTARL', 'NP3SPCH', 'PTCGBOTH', 'STAIAD1', 'STAIAD10',\n",
    "    'STAIAD11', 'STAIAD12', 'STAIAD13', 'STAIAD14', 'STAIAD15', 'STAIAD16',\n",
    "    'STAIAD17', 'STAIAD18', 'STAIAD19', 'STAIAD2', 'STAIAD20', 'STAIAD21',\n",
    "    'STAIAD22', 'STAIAD23', 'STAIAD24', 'STAIAD25', 'STAIAD26', 'STAIAD27',\n",
    "    'STAIAD28', 'STAIAD29', 'STAIAD3', 'STAIAD30', 'STAIAD31', 'STAIAD32',\n",
    "    'STAIAD33', 'STAIAD34', 'STAIAD35', 'STAIAD36', 'STAIAD37', 'STAIAD38',\n",
    "    'STAIAD39', 'STAIAD4', 'STAIAD40', 'STAIAD5', 'STAIAD6', 'STAIAD7',\n",
    "    'STAIAD8', 'STAIAD9'\n",
    "]\n",
    "\n",
    "selected_columns = [\"PATNO\", \"AGE_AT_VISIT\", \"FINAL_SEX_ENCODED\", \"COHORT\"] + ordinal_vars + [\"EVENT_ID\"]\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "# 5) Extract PD/Prodromal\n",
    "df_pd = df[df[\"COHORT\"].isin([\"PD\", \"Prodromal\"])].copy()\n",
    "print(f\"Healthy controls: {df_healthy.shape[0]} | PD/Prodromal: {df_pd.shape[0]}\")\n",
    "\n",
    "# 6) Drop biomarkers with >20% missing\n",
    "null_fraction = df_pd[ordinal_vars].isna().mean()\n",
    "cols_to_drop = list(null_fraction[null_fraction > 0.20].index)\n",
    "ordinal_vars = [v for v in ordinal_vars if v not in cols_to_drop]\n",
    "df_pd.drop(columns=cols_to_drop, inplace=True)\n",
    "df_healthy.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 7) Drop biomarkers with only one unique value\n",
    "low_variance_vars = [v for v in ordinal_vars if df_pd[v].nunique() <= 1]\n",
    "if low_variance_vars:\n",
    "    print(f\"Dropping low-variance biomarkers: {low_variance_vars}\")\n",
    "    ordinal_vars = [v for v in ordinal_vars if v not in low_variance_vars]\n",
    "    df_pd.drop(columns=low_variance_vars, inplace=True)\n",
    "    df_healthy.drop(columns=low_variance_vars, inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"Remaining biomarkers after filtering: {len(ordinal_vars)}\")\n",
    "\n",
    "# 8) Drop rows with missing values\n",
    "df_pd.dropna(subset=ordinal_vars, inplace=True)\n",
    "df_healthy.dropna(subset=ordinal_vars, inplace=True)\n",
    "\n",
    "# 9) Create data matrices\n",
    "data_mat_healthy = df_healthy[ordinal_vars].astype(float).values\n",
    "data_mat_pd = df_pd[ordinal_vars].astype(float).values\n",
    "n_samples = data_mat_pd.shape[0]\n",
    "n_biomarkers = data_mat_pd.shape[1]\n",
    "\n",
    "# 10) Build score matrix\n",
    "def get_score_vals_padded(data_mat_healthy, data_mat_pd):\n",
    "    combined_data = np.vstack([data_mat_healthy, data_mat_pd])\n",
    "    n_biomarkers = combined_data.shape[1]\n",
    "    max_scores_per_biomarker = [int(combined_data[:, b].max()) + 1 for b in range(n_biomarkers)]\n",
    "    max_num_scores = max(max_scores_per_biomarker)\n",
    "    score_vals = np.zeros((n_biomarkers, max_num_scores), dtype=int)\n",
    "    for b in range(n_biomarkers):\n",
    "        valid_scores = np.arange(0, max_scores_per_biomarker[b])\n",
    "        score_vals[b, :len(valid_scores)] = valid_scores\n",
    "    return score_vals\n",
    "\n",
    "score_vals = get_score_vals_padded(data_mat_healthy, data_mat_pd)\n",
    "\n",
    "# 11) Compute prob_nl\n",
    "prob_nl = np.zeros((n_samples, n_biomarkers))\n",
    "for j in range(n_biomarkers):\n",
    "    vals = data_mat_healthy[:, j]\n",
    "    mu, sigma = np.mean(vals), np.std(vals)\n",
    "    sigma = sigma if sigma > 0 else 0.1\n",
    "    prob_nl[:, j] = norm.pdf(data_mat_pd[:, j], loc=mu, scale=sigma)\n",
    "\n",
    "# 12) Build p_score_dist matrix\n",
    "score_vals_flat = sorted(set(np.unique(score_vals)))\n",
    "N_scores = len(score_vals_flat)\n",
    "p_score_dist = np.zeros((N_scores, N_scores + 1))  # rows = true scores (1 to N), cols = observed (0 to N)\n",
    "for z in range(1, N_scores + 1):  # true score from 1 to N_scores\n",
    "    for s in range(N_scores + 1):  # observed score from 0 to N_scores\n",
    "        p_score_dist[z - 1, s] = norm.pdf(s, loc=z, scale=1.0)\n",
    "    p_score_dist[z - 1] /= np.sum(p_score_dist[z - 1])  # normalize\n",
    "\n",
    "# 13) Compute prob_score\n",
    "def compute_prob_score(data_mat_pd, p_score_dist):\n",
    "    n_samples, n_biomarkers = data_mat_pd.shape\n",
    "    N_scores = p_score_dist.shape[0]\n",
    "    prob_score = np.zeros((n_samples, n_biomarkers, N_scores))\n",
    "    for z in range(N_scores):\n",
    "        for s in range(N_scores + 1):\n",
    "            match_indices = (data_mat_pd == s)\n",
    "            prob_score[match_indices, z] = p_score_dist[z, s]\n",
    "    return prob_score\n",
    "\n",
    "prob_score = compute_prob_score(data_mat_pd, p_score_dist)\n",
    "\n",
    "# 14) Check for NaNs\n",
    "print(\"NaNs in prob_nl:\", np.isnan(prob_nl).sum())\n",
    "print(\"NaNs in prob_score:\", np.isnan(prob_score).sum())\n",
    "if np.isnan(prob_nl).any() or np.isnan(prob_score).any():\n",
    "    raise ValueError(\"There are NaNs in the probability matrices. Please check data preprocessing.\")\n",
    "\n",
    "# 15) Output directory\n",
    "output_folder = \"./ordinal_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 16) Run SuStaIn\n",
    "model = OrdinalSustain(\n",
    "    prob_nl=prob_nl,\n",
    "    prob_score=prob_score,\n",
    "    score_vals=score_vals,\n",
    "    biomarker_labels=ordinal_vars,\n",
    "    N_startpoints=25,\n",
    "    N_S_max=2,\n",
    "    N_iterations_MCMC=int(1e4),\n",
    "    output_folder=output_folder,\n",
    "    dataset_name=\"PD_ordinal_V08\",\n",
    "    use_parallel_startpoints=False,\n",
    "    seed=42\n",
    ")\n",
    "model.run_sustain_algorithm()\n",
    "\n",
    "# 17) Plot results\n",
    "figs, axs = model.plot_sustain_model(\n",
    "    samples_sequence=model.samples_sequence,\n",
    "    samples_f=model.samples_f,\n",
    "    n_samples=n_samples,\n",
    "    score_vals=score_vals,\n",
    "    biomarker_labels=ordinal_vars,\n",
    "    ml_f_EM=model.ml_f,\n",
    "    separate_subtypes=False\n",
    ")\n",
    "\n",
    "for i, fig in enumerate(figs):\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(output_folder, f\"sustain_plot_{i}.png\"))\n",
    "    plt.show()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
